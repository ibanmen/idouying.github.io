elasticsearch系列一：elasticsearch（ES简介、安装&配置、集成Ikanalyzer）
===

## ES简介

1. ES是什么？

Elasticsearch 是一个开源的搜索引擎，建立在全文搜索引擎库 Apache Lucene 基础之上

用 Java 编写的，它的内部使用 Lucene 做索引与搜索，但是它的目的是使全文检索变得简单， 通过隐藏 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API。

Elasticsearch 不仅仅只是一个全文搜索引擎。 它可以被下面这样准确的形容：

一个分布式的实时文档存储，每个字段可以被索引与搜索——作数据库用

一个分布式实时分析搜索引擎

能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据

2. ES的诞生

原文链接: https://www.elastic.co/guide/cn/elasticsearch/guide/current/intro.html

3. ES的发展历程

Elasticsearch 后来作为一家公司（Elastic公司）进行运作，定位为数据搜索和分析平台。在2014年6月获得7000万美元融资，累积融资过亿美元。

ES现在可以与Java、Ruby、Python、PHP、Perl、.NET等多种客户端集成。也可与Hadoop、Spark等大数据分析平台进行集成，功能十分强大。

基于Elasticsearch衍生出了一系列开源软件，统称为 Elatic Stack

说明：

因为logstash比较耗内存，所以用Beats来替代

为避免版本混乱，从5.0开始，Elastic公司将各组件的版本号统一。使用时，各组件版本号应一致（版本号形式：x.y.z，z可以不同）。

4. ES的特性

官网的介绍： https://www.elastic.co/cn/products/elasticsearch

速度快、易扩展、弹性、灵活、操作简单、多语言客户端、X-Pack、hadoop/spark强强联手、开箱即用。

- 分布式：横向扩展非常灵活
- 全文检索：基于lucene的强大的全文检索能力；
- 近实时搜索和分析：数据进入ES，可达到近实时搜索，还可进行聚合分析
- 高可用：容错机制，自动发现新的或失败的节点，重组和重新平衡数据
- 模式自由：ES的动态mapping机制可以自动检测数据的结构和类型，创建索引并使数据可搜索。
- RESTful API：JSON + HTTP

5. ES的应用场景

- 站内搜索
- NoSQL 数据库
- 日志分析
- 数据分析

6. ES的架构

![1][1]

说明:

- Gateway是ES用来存储索引的文件系统，支持多种类型。
- Gateway的上层是一个分布式的lucene框架。
- Lucene之上是ES的模块，包括：索引模块、搜索模块、映射解析模块等
- ES模块之上是 Discovery、Scripting和第三方插件。Discovery是ES的节点发现模块，不同机器上的ES节点要组成集群需要进行消息通信，集群内部需要选举master节点，这些工作都是由Discovery模块完成。支持多种发现机制，如 Zen 、EC2、gce、Azure。Scripting用来支持在查询语句中插入javascript、python等脚本语言，scripting模块负责解析这些脚本，使用脚本语句性能稍低。ES也支持多种第三方插件。
- 再上层是ES的传输模块和JMX.传输模块支持多种传输协议，如 Thrift、memecached、http，默认使用http。JMX是java的管理框架，用来管理ES应用。
- 最上层是ES提供给用户的接口，可以通过RESTful接口和ES集群进行交互。

7. ES的核心概念

- Near Realtime（NRT） 近实时。数据提交索引后，立马就可以搜索到。
- Cluster 集群，一个集群由一个唯一的名字标识，默认为“elasticsearch”。集群名称非常重要，具有相同集群名的节点才会组成一个集群。集群名称可以在配置文件中指定。
- Node 节点：存储集群的数据，参与集群的索引和搜索功能。像集群有名字，节点也有自己的名称，默认在启动时会以一个随机的UUID的前七个字符作为节点的名字，你可以为其指定任意的名字。通过集群名在网络中发现同伴组成集群。一个节点也可是集群。
- Index 索引: 一个索引是一个文档的集合（等同于solr中的集合）。每个索引有唯一的名字，通过这个名字来操作它。一个集群中可以有任意多个索引。
- Type 类型：指在一个索引中，可以索引不同类型的文档，如用户数据、博客数据。从6.0.0 版本起已废弃，一个索引中只存放一类数据。
- Document 文档：被索引的一条数据，索引的基本信息单元，以JSON格式来表示。
- Shard 分片：在创建一个索引时可以指定分成多少个分片来存储。每个分片本身也是一个功能完善且独立的“索引”，可以被放置在集群的任意节点上。分片的好处：
- 允许我们水平切分/扩展容量
- 可在多个分片上进行分布式的、并行的操作，提高系统的性能和吞吐量。

> 注意：分片数创建索引时指定，创建后不可改了。备份数可以随时改。

Replication 备份: 一个分片可以有多个备份（副本）。备份的好处：

- 高可用。一个主分片挂了，副本分片就顶上去
- 扩展搜索的并发能力、吞吐量。搜索可以在所有的副本上并行运行。-高并发下副本也可搜索

8. 为了方便理解，作一个ES和数据库的对比

![2][2]

9. ES学习资源

官网的文档是最好的学习资源，详细、全面，官网还提供有一些视频：
https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html

官网中还提供一个中文的权威指南，可以学习，（版本稍老了点是基于2.0的）：
https://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html

## 安装&配置

1. ES安装包

官网下载地址： https://www.elastic.co/downloads/elasticsearch

2. JDK要求

 JDK版本： 1.8

3. 在linux上安装示例

注意：ES不能以root用户身份运行 确保运行用户对各使用到的目录的权限

3.1 获取安装包

版本 6.2.4

```bash
curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.2.4.tar.gz
```

3.2 解压到安装目录

```bash
tar -xvf elasticsearch-6.2.4.tar.gz -C /opt
```

3.3 配置

3.4 启动

```bash
cd  /opt/elasticsearch-6.2.4/bin
./elasticsearch
```

启动时指定参数：

```bash
./elasticsearch -Ecluster.name=my_cluster_name -Enode.name=my_node_name
```

了解启动脚本可用选项：

```bash
./elasticsearch -h
```

4. 在linux 虚拟机上运行可能的失败问题

4.1 内存不够用，默认es配置使用1G堆内存，如果的你学习用的虚拟机没有这么大的内存，请在config/jvm.options中调整

4.2 可能会报如下的错误：

![3][3]

解决方法如下：

问题一：max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]

解决：修改切换到root用户修改配置limits.conf 添加下面两行

命令:vi /etc/security/limits.conf

```bash
* hard nofile 65536
* soft nofile 65536
```

问题二：max number of threads [1024] for user [lish] likely too low, increase to at least [2048]

解决：切换到root用户，进入limits.d目录下修改配置文件。

vi /etc/security/limits.d/90-nproc.conf

修改如下内容：

```bash
* soft nproc 1024
#修改为
* soft nproc 2048
```

问题三：max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]

解决：切换到root用户修改配置sysctl.conf

vi /etc/sysctl.conf

添加下面配置：

```bash
vm.max_map_count=655360
```

并执行命令：

```bash
sysctl -p
```

切换到es的用户。

然后，重新启动elasticsearch，即可启动成功。

5. ES端口说明

- 9200 对外服务的http 端口
- 9300 节点间通信的tcp端口

6. 后台运行ES

使用守护进程运行：`./elasticsearch -d`


7. 关闭ES

非后台运行的：`ctrl + c`

后台运行的（守护进程运行）：`kill es进程`

8. 在windows中启动

```bat
elasticsearch.bat
```

启动以后访问地址：http://localhost:9200/

9. ES软件目录说明

![4][4]

10. ES 配置说明

10.1 配置文件分离

配置文件目录默认为：$ES_HOME/config，如果需要配置文件与软件分离（方便升级），可以通过 ES_PATH_CONF 环境变量来指定。如你可以在命令行指定声明：

![5][5]

10.2 yml 格式说明

![6][6]

10.3 Jvm参数格式说明

![7][7]

11. ES 重要的配置参数

11.1 数据目录和日志目录，生成环境下应与软件分离

![8][8]

11.2 所属的集群名，默认为 elasticsearch ，可自定义

```yaml
cluster.name: logging-prod
```

11.3 节点名，默认为 UUID前7个字符，可自定义

```yaml
node.name: prod-data-2
```

以主机名作节点名：

```yaml
node.name: ${HOSTNAME}
```

11.4 network.host  IP绑定

默认绑定的是["127.0.0.1", "[::1]"]回环地址，集群下要服务间通信，需绑定一个ipv4或ipv6地址

```yaml
network.host: 192.168.1.10
```

11.5 http.port: 9200-9300

对外服务的http 端口， 默认 9200-9300 。可以为它指定一个值或一个区间，当为区间时会取用区间第一个可用的端口。

11.6  transport.tcp.port: 9300-9400

节点间交互的端口， 默认 9300-9400 。可以为它指定一个值或一个区间，当为区间时会取用区间第一个可用的端口。

11.7 Discovery Config  节点发现配置

ES中默认采用的节点发现方式是  zen（基于组播（多播）、单播）。在应用于生产前有两个重要参数需配置：

discovery.zen.ping.unicast.hosts: ["host1","host2:port","host3[portX-portY]"] 单播模式下，设置具有master资格的节点列表，新加入的节点向这个列表中的节点发送请求来加入集群

discovery.zen.minimum_master_nodes: 1 这个参数控制的是，一个节点需要看到具有master资格的节点的最小数量，然后才能在集群中做操作。官方的推荐值是(N/2)+1，其中N是具有master资格的节点的数量。

11.8 Jvm heap 大小设置

生产环境中一定要在jvm.options中调大它的jvm内存。

11.9 JVM heap dump path 设置

生产环境中指定当发生OOM异常时，heap的dump path，好分析问题。在jvm.options中配置：

-XX:HeapDumpPath=/var/lib/elasticsearch

11.10 其他配置

```txt
transport.tcp.compress: false
    是否压缩tcp传输的数据，默认false
http.cors.enabled: true
    是否使用http协议对外提供服务，默认true
http.max_content_length: 100mb
    http传输内容的最大容量，默认100mb
node.master: true   
    指定该节点是否可以作为master节点，默认是true。ES集群默认是以第一个节点为master，如果该节点出故障就会重新选举master。
node.data: true
    该节点是否存索引数据，默认true。
discover.zen.ping.timeout: 3s
    设置集群中自动发现其他节点时ping连接超时时长，默认为3秒。在网络环境较差的情况下，增加这个值，会增加节点等待响应的时间，从一定程度上会减少误判。
discovery.zen.ping.multicast.enabled: false
    是否启用多播来发现节点。
```

12. 安装Kibana

 Kibana是ES的可视化管理工具

12.1 下载安装包

一定和ES的版本一致（ 6.2.4)

https://www.elastic.co/downloads/kibana

12.2 安装

解压到安装目录即可

12.3 配置

在config/kibana.yml中配置 elasticsearch.url的值为 ES的访问地址

12.4 启动

./bin/kibana

访问地址：http://localhost:5601

## 集成Ikanalyzer 

1. 获取 ES-IKAnalyzer插件

一定和ES的版本一致（ 6.2.4)

地址： https://github.com/medcl/elasticsearch-analysis-ik/releases

2. 安装插件

将 ik 的压缩包解压到 ES安装目录的plugins/目录下（最好把解出的目录名改一下，防止安装别的插件时同名冲突），然后重启ES。

3. 扩展词库

配置文件config/IKAnalyzer.cfg.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
    <comment>IK Analyzer 扩展配置</comment>
    <!--用户可以在这里配置自己的扩展字典 -->
    <entry key="ext_dict">custom/mydict.dic;custom/single_word_low_freq.dic</entry>
     <!--用户可以在这里配置自己的扩展停止词字典-->
    <entry key="ext_stopwords">custom/ext_stopword.dic</entry>
    <!--用户可以在这里配置远程扩展字典 远程词库，可热更新，在一处地方维护-->
    <!-- <entry key="remote_ext_dict">words_location</entry> -->
    <!--用户可以在这里配置远程扩展停止词字典-->
    <!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>
```

4. 测试 IK

1、创建一个索引

```bash
curl -XPUT http://localhost:9200/index
```

2、创建一个映射mapping

```bash
curl -XPOST http://localhost:9200/index/fulltext/_mapping -H 'Content-Type:application/json' -d'
{
        "properties": {
            "content": {
                "type": "text",
                "analyzer": "ik_max_word",
                "search_analyzer": "ik_max_word"
            }
        }
}'
```

3、索引一些文档

```bash
curl -XPOST http://localhost:9200/index/fulltext/1 -H 'Content-Type:application/json' -d' {"content":"美国留给伊拉克的是个烂摊子吗"}'

curl -XPOST http://localhost:9200/index/fulltext/2 -H 'Content-Type:application/json' -d' {"content":"公安部：各地校车将享最高路权"}'

curl -XPOST http://localhost:9200/index/fulltext/3 -H 'Content-Type:application/json' -d' {"content":"中韩渔警冲突调查：韩警平均每天扣1艘中国渔船"}'
```

**总结**

安装的ES、Kibana和中文分词器的版本一定要一致，否则会不能使用

> 原文：https://www.cnblogs.com/leeSmall/p/9189078.html

[1]: ./img/es/01/1.png
[2]: ./img/es/01/2.png
[3]: ./img/es/01/3.png
[4]: ./img/es/01/4.png
[5]: ./img/es/01/5.png
[6]: ./img/es/01/6.png
[7]: ./img/es/01/7.png
[8]: ./img/es/01/8.png
