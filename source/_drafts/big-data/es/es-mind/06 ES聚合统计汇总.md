# 06 ES聚合统计汇总

https://www.elastic.co/guide/cn/elasticsearch/guide/current/_buckets_inside_buckets.html

（数量聚合、最大值、最小值、平均值、求和等聚合操作）

## 聚合分类

### Bucket Aggregations

- 一些列满足特定条件的文档的集合
- 类似于 SQL 的分组（GROUP BY）

### Metrics Aggregations

- 一些数学运算，对文档字段进行统计分析
- 类似于 sql 的 COUNT() 、 SUM() 、 MAX() 等统计方法。

### Pipeline Aggregations

管道聚合工作于其他聚合而不是文档集所产生的输出，从而将信息添加到输出树中。

管道聚合有很多不同类型，每种类型都与其他聚合计算不同的信息，将这些类型分为两类：

Parent：
父级聚合的输出提供了一组管道聚合，它可以计算新的存储桶或新的聚合以添加到现有存储桶中。

Sibling：
同级聚合的输出提供的管道聚合，并且能够计算与该同级聚合处于同一级别的新聚合。

管道聚合不能具有子聚合，但是根据其类型，它可以引用buckets_path 允许管道聚合链接的另一个管道。例如，您可以将两个导数链接在一起以计算第二个导数（即导数的导数）。

- 对其他聚合结果进行二次聚合

### Matrix Aggregations


此功能是试验性的，在将来的版本中可能会完全更改或删除。Elastic会尽力解决所有问题，但是实验性功能不受官方GA功能的支持SLA约束。

- 支持对多个字段的操作并提供一个结果矩阵
- Matrix Stats

  该matrix_stats聚合是指将计算在一组文档领域的下列统计数据的数字汇总：
  
  count
  
  计算中包括的每野外采样数。
  
  mean
  
  每个字段的平均值。
  
  variance
  
  每场测量样本从均值分布的程度。
  
  skewness
  
  每场测量可量化均值周围的不对称分布。
  
  kurtosis
  
  每场测量可量化分布的形状。
  
  covariance
  
  定量描述一个领域中的变化如何与另一个领域相关联的矩阵。
  
  correlation
  
  协方差矩阵缩放到-1到1（含）范围。描述场分布之间的关系。

## 聚合的作用范围

### Filter

- 过滤桶

   假设我们正在为汽车经销商创建一个搜索页面， 我们希望显示用户搜索的结果，但是我们同时也想在页面上提供更丰富的信息，包括（与搜索匹配的）上个月度汽车的平均售价。
  
  这里我们无法简单的做范围限定，因为有两个不同的条件。搜索结果必须是 ford ，但是聚合结果必须满足 ford AND sold > now - 1M 。
  
  为了解决这个问题，我们可以用一种特殊的桶，叫做 filter （注：过滤桶） 。 我们可以指定一个过滤桶，当文档满足过滤桶的条件时，我们将其加入到桶内。

	- 只对聚合结果过滤-示例

	  GET /cars/transactions/_search
	  {
	     "size" : 0,
	     "query":{
	        "match": {
	           "make": "ford"
	        }
	     },
	     "aggs":{
	        "recent_sales": {
	           "filter": { （使用 过滤 桶在 查询 范围基础上应用过滤器。）
	              "range": {
	                 "sold": {
	                    "from": "now-1M"
	                 }
	              }
	           },
	           "aggs": {
	              "average_price":{
	                 "avg": {（avg 度量只会对 ford 和上个月售出的文档计算平均售价。）
	                    "field": "price" 
	                 }
	              }
	           }
	        }
	     }
	  }
	  
	  
	  
	  
	  

### Post_Filter

- 只过滤搜索结果，不过滤聚合结果

	- 后过滤器

	  post_filter （只影响搜索结果，不影响聚合）
	  它是接收一个过滤器的顶层搜索请求元素。这个过滤器在查询 之后 执行（这正是该过滤器的名字的由来：它在查询之后 post 执行）。正因为它在查询之后执行，它对查询范围没有任何影响，所以对聚合也不会有任何影响。
	  
	  当你需要对搜索结果和聚合结果做不同的过滤时，你才应该使用 post_filter ，
	   有时用户会在普通搜索使用 post_filter 。不要这么做！ post_filter 的特性是在查询 之后 执行，任何过滤对性能带来的好处（比如缓存）都会完全失去。

	- 示例

	  GET /cars/transactions/_search
	  {
	      "size" : 0,
	      "query": {
	          "match": {
	              "make": "ford"
	          }
	      },
	      "post_filter": {    
	          "term" : {
	              "color" : "green"
	          }
	      },
	      "aggs" : {
	          "all_colors": {
	              "terms" : { "field" : "color" }
	          }
	      }
	  }

### Global

在搜索执行上下文中定义所有文档的单个存储桶

POST /sales/_search?size=0
{
    "query" : {
        "match" : { "type" : "t-shirt" }
    },
    "aggs" : {
        "all_products" : {
            "global" : {}, 
            "aggs" : { 
                "avg_price" : { "avg" : { "field" : "price" } }
            }
        },
        "t_shirts": { "avg" : { "field" : "price" } }
    }
}

- 无视query，对所有文档进行聚合

##  多桶排序

### 默认排序

多值桶（ terms 、 histogram 和 date_histogram ）动态生成很多桶。 Elasticsearch 是如何决定这些桶展示给用户的顺序呢？

默认的，桶会根据 doc_count 降序排列。

### 内置排序

GET /cars/transactions/_search
{
    "size" : 0,
    "aggs" : {
        "colors" : {
            "terms" : {
              "field" : "color",
              "order": {
                "_count" : "asc" 
              }
            }
        }
    }
}

我们为聚合引入了一个 order 对象， 它允许我们可以根据以下几个值中的一个值进行排序：

_count
按文档数排序。对 terms 、 histogram 、 date_histogram 有效。

_term
按词项的字符串值的字母顺序排序。只在 terms 内使用。

_key
按每个桶的键值数值排序（理论上与 _term 类似）。 只在 histogram 和 date_histogram 内使用。

### 按度量排序

GET /cars/transactions/_search
{
    "size" : 0,
    "aggs" : {
        "colors" : {
            "terms" : {
              "field" : "color",
              "order": {
#桶按照计算平均值的升序排序
                "avg_price" : "asc" 
              }
            },
            "aggs": {
                "avg_price": {
#计算每个桶的平均售价。
                    "avg": {"field": "price"} 
                }
            }
        }
    }
}

### 基于“深度”度量排序

- 嵌套路径

  将度量用尖括号（ > ）嵌套起来，像这样： my_bucket>another_bucket>metric 
  
  
  需要提醒的是嵌套路径上的每个桶都必须是 单值 的。 filter 桶生成 一个单值桶：所有与过滤条件匹配的文档都在桶中。 多值桶（如：terms ）动态生成许多桶，无法通过指定一个确定路径来识别。
  
  目前，只有三个单值桶： filter 、 global 和 reverse_nested 

- 示例

  GET /cars/transactions/_search
  {
      "size" : 0,
      "aggs" : {
          "colors" : {
              "histogram" : {
                "field" : "price",
                "interval": 20000,
                "order": {
                  "red_green_cars>stats.variance" : "asc" 
                }
              },
              "aggs": {
                  "red_green_cars": {
                      "filter": { "terms": {"color": ["red", "green"]}}, 
                      "aggs": {
                          "stats": {"extended_stats": {"field" : "price"}} 
                      }
                  }
              }
          }
      }
  }
  
  本例中，可以看到我们如何访问一个嵌套的度量。 stats 度量是 red_green_cars 聚合的子节点，而 red_green_cars 又是 colors 聚合的子节点。 为了根据这个度量排序，
  
  我们定义了路径 red_green_cars>stats.variance 。我们可以这么做，因为 filter 桶是个单值桶。
  
  

## 聚合的精度问题

### 三角因子模型

数据可以存入单台机器的内存之中，我们可以随心所欲，使用任何想用的算法。结果会 100% 精确，响应会相对快速。

- 大数据、精确性和实时性
- 精确 + 实时
- 大数据 + 精确

  传统的 Hadoop。可以处理 PB 级的数据并且为我们提供精确的答案，但它可能需要几周的时间才能为我们提供这个答案。

- 大数据 + 实时

  近似算法为我们提供准确但不精确的结果。

- 模型图

## 缓存聚合结果

### Caching heavy aggregations

可以将常用聚合（例如，用于显示在网站首页上）进行缓存，以加快响应速度。这些缓存结果与未缓存聚合返回的结果相同-您将永远不会获得过时的结果。

缓存设置：
https://www.elastic.co/guide/en/elasticsearch/reference/7.7/caching-heavy-aggregations.html

##  Doc Values and Fielddata

在规划时，组织好数据，使聚合运行在 not_analyzed 字符串而不是 analyzed 字符串，这样可以有效的利用 doc values 。

### Doc Values

倒排索引将词项映射到包含它们的文档，

doc values 将文档映射到它们包含的词项：

Doc      Terms
--------------------------------------
Doc_1 | brown, dog, fox, jumped, lazy, over, quick, the

Doc_2 | brown, dogs, foxes, in, lazy, leap, over, quick, summer

Doc_3 | dog, dogs, fox, jumped, over, quick, the

搜索和聚合是相互紧密缠绕的。搜索使用倒排索引查找文档，聚合操作收集和聚合 doc values 里的数据。

- 深入理解

  Doc Values 是在索引时与 倒排索引 同时生成。也就是说 Doc Values 和 倒排索引 一样，基于 Segement 生成并且是不可变的。同时 Doc Values 和 倒排索引 一样序列化到磁盘，这样对性能和扩展性有很大帮助。
  
  Doc Values 通过序列化把数据结构持久化到磁盘，我们可以充分利用操作系统的内存，而不是 JVM 的 Heap 。 当 working set 远小于系统的可用内存，系统会自动将 Doc Values 驻留在内存中，使得其读写十分快速；不过，当其远大于可用内存时，系统会根据需要从磁盘读取 Doc Values，然后选择性放到分页缓存中。很显然，这样性能会比在内存中差很多，但是它的大小就不再局限于服务器的内存了。

- 列式存储 的压缩

  列式存储 适用于聚合、排序、脚本等操作。

	- 压缩模式:

	  Doc Values 在压缩过程中使用如下技巧。它会按依次检测以下压缩模式:
	  
	  1、如果所有的数值各不相同（或缺失），设置一个标记并记录这些值
	  
	  2、如果这些值小于 256，将使用一个简单的编码表
	  
	  3、如果这些值大于 256，检测是否存在一个最大公约数
	  
	  4、如果没有存在最大公约数，从最小的数值开始，统一计算偏移量进行编码

- 禁用 Doc Values

  Doc Values 默认对所有字段启用，除了 analyzed strings。也就是说所有的数字、地理坐标、日期、IP 和不分析（ not_analyzed ）字符类型都会默认开启。
  
  如果你知道你永远也不会对某些字段进行聚合、排序或是使用脚本操作？ 尽管这并不常见，但是你可以通过禁用特定字段的 Doc Values 。这样不仅节省磁盘空间，也许会提升索引的速度。
  
  
  PUT my_index
  {
    "mappings": {
      "my_type": {
        "properties": {
          "session_id": {
            "type":       "string",
            "index":      "not_analyzed",
            "doc_values": false 
  #这个字段将不能被用于聚合、排序以及脚本操作
          }
        }
      }
    }
  }
  
  

	- 不能被用于聚合、排序以及脚本操作

- 禁用 index

	- 不能被查询

	  PUT my_index
	  {
	    "mappings": {
	      "my_type": {
	        "properties": {
	          "customer_token": {
	            "type":       "string",
	            "index":      "not_analyzed",
	            "doc_values": true, 
	            "index": "no" 
	          }
	        }
	      }
	    }
	  }
	  
	  通过设置 doc_values: true 和 index: no ，我们得到一个只能被用于聚合/排序/脚本的字段。

### 聚合与分析

因此，在聚合字符串字段之前，请评估情况：

这是一个 not_analyzed 字段吗？如果是，可以通过 doc values 节省内存 。
否则，这是一个 analyzed 字段，它将使用 fielddata 并加载到内存中。这个字段因为 ngrams 有一个非常大的基数？如果是，这对于内存来说极度不友好。

- "index": "not_analyzed"
- fielddata 

	- fielddata 构建和管理 100% 在内存中，常驻于 JVM 内存堆。

### 限制内存使用

一旦分析字符串被加载到 fielddata ，他们会一直在那里，直到被驱逐（或者节点崩溃）。

Fielddata 是 延迟 加载。如果你从来没有聚合一个分析字符串，就不会加载 fielddata 到内存中。

此外，fielddata 是基于字段加载的， 这意味着只有很活跃地使用字段才会增加 fielddata 的负担。

在设置 Elasticsearch 堆大小时需要通过 $ES_HEAP_SIZE 环境变量应用两个规则：

1、不要超过可用 RAM 的 50%

Lucene 能很好利用文件系统的缓存，它是通过系统内核管理的。如果没有足够的文件系统缓存空间，性能会受到影响。 此外，专用于堆的内存越多意味着其他所有使用 doc values 的字段内存越少。


2、不要超过 32 GB

如果堆大小小于 32 GB，JVM 可以利用指针压缩，这可以大大降低内存的使用：每个指针 4 字节而不是 8 字节。

-  fielddata  的大小

  indices.fielddata.cache.size 
  控制为 fielddata 分配的堆空间大小
  
  如果结果中 fielddata 大小超过了指定 大小 ，其他的值将会被回收从而获得空间。
  
  fielddata 不是临时缓存。它是驻留内存里的数据结构，必须可以快速执行访问，而且构建它的代价十分高昂。如果每个请求都重载数据，性能会十分糟糕。

- 监控 fielddata 

  按索引使用 indices-stats API ：
  
  GET /_stats/fielddata?fields=*
  
  
  按节点使用 nodes-stats API ：
  
  GET /_nodes/stats/indices/fielddata?fields=*
  
  按索引节点：
  GET /_nodes/stats/indices/fielddata?level=indices&fields=*
  使用设置 ?fields=* ，可以将内存使用分配到每个字段。

### Fielddata 的过滤

PUT /music/_mapping/song
{
  "properties": {
    "tag": {
      "type": "string",
      "fielddata": { 
        "filter": {
          "frequency": { 
            "min":              0.01, 
            "min_segment_size": 500  
          }
        }
      }
    }
  }
}

fielddata 关键字允许我们配置 fielddata 处理该字段的方式。


frequency 过滤器允许我们基于项频率过滤加载 fielddata。


只加载那些至少在本段文档中出现 1% 的项。


忽略任何文档个数小于 500 的段。

### 预加载 fielddata

### 优化聚合查询

- 默认配置：深度优先

	-  先构建完整的树，然后修剪无用节点。

-  广度优先

  要使用广度优先，只需简单 的通过参数 collect 开启：
  
  {
    "aggs" : {
      "actors" : {
        "terms" : {
           "field" :        "actors",
           "size" :         10,
           "collect_mode" : "breadth_first" 
        },
        "aggs" : {
          "costars" : {
            "terms" : {
              "field" : "actors",
              "size" :  5
            }
          }
        }
      }
    }
  }

	- 它先执行第一层聚合， 再 继续下一层聚合之前会先做修剪
	- 适用于

	  广度优先仅仅适用于每个组的聚合数量远远小于当前总组数的情况下，因为广度优先会在内存中缓存裁剪后的仅仅需要缓存的每个组的所有数据，以便于它的子聚合分组查询可以复用上级聚合的数据。

- 对比分析

  广度优先的内存使用情况与裁剪后的缓存分组数据量是成线性的。对于很多聚合来说，每个桶内的文档数量是相当大的。 想象一种按月分组的直方图，总组数肯定是固定的，因为每年只有12个月，这个时候每个月下的数据量可能非常大。这使广度优先不是一个好的选择，这也是为什么深度优先作为默认策略的原因。
  
  针对上面演员的例子，如果数据量越大，那么默认的使用深度优先的聚合模式生成的总分组数就会非常多，但是预估二级的聚合字段分组后的数据量相比总的分组数会小很多，所以这种情况下使用广度优先的模式能大大节省内存，从而通过优化聚合模式来大大提高了在某些特定场景下聚合查询的成功率。

