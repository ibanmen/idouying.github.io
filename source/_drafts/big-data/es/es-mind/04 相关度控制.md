# 04 相关度控制

## 1、什么是相关性

打分的本质是排序，需要把最符合⽤户需求的⽂档排在前⾯。ES 5 之前，默认的相关性算分
采⽤ TF-IDF，现在采⽤BM25

https://www.elastic.co/guide/en/elasticsearch/reference/5.0/breaking_50_search_changes.html  官网版本改变说明

### 描述了⼀个⽂档和查询语句匹配的程度。

### ES 会对每个匹配查询条件的结果进⾏算分 _score

### _score 的评分越高，相关度越高。

### 衡量相关性

- 查准率 Precision

	- 尽可能返回较少的无关文档

- 查全率 Recall

	- 尽可能返回较多的相关文档

- 排序 Ranking

	- 按相关性排序

## 2、核心概念

### 1）词频 TF
 Term Frequency

- 词在文档中出现的频度是多少
- 出现频率越高，相关性也越高。

	-  字段中出现过 5 次要比只出现过 1 次的相关性高。

- tf(t in d) = √frequency

	- 词 t 在文档 d 的词频（ tf ）是该词在文档中出现次数的平方根。

- 将参数 index_options 设置为 docs 可以禁用词频统计及词频位置

  这个映射的字段不会计算词的出现次数，对于短语或近似查询也不可用。要求精确查询的 not_analyzed 字符串字段会默认使用该设置。
  
  PUT /my_index
  {
    "mappings": {
      "doc": {
        "properties": {
          "text": {
            "type":          "string",
            "index_options": "docs" 
          }
        }
      }
    }
  }

### 2）逆向⽂档频率 IDF
 Inverse Document Frequency

- 每个检索词在索引中出现的频率
- 频率越高，相关性越低。

	- 检索词出现在多数文档中会比出现在少数文档中的权重更低。

- idf(t) = 1 + log ( numDocs / (docFreq + 1)) 

	- 词 t 的逆向文档频率（ idf ）是：索引中文档数量除以所有包含该词的文档数，然后求其对数。

### 3）字段长度准则 fieldNorm

- 字段的长度是多少
- 长度越长，相关性越低。

	- 检索词出现在一个短的 title 要比同样的词出现在一个长的 content 字段权重更大。

- norm(d) = 1 / √numTerms

	- 字段长度归一值（ norm ）是字段中词数平方根的倒数。

- 可以通过修改字段映射禁用归一值

  PUT /my_index
  {
    "mappings": {
      "doc": {
        "properties": {
          "yourField": {
            "type": "text",
            "norms": { "enabled": false } 
          }
        }
      }
    }
  }
  
  
  
  这个 yourField 字段不会将字段长度归一值考虑在内，长字段和短字段会以相同长度计算评分。
  
  无论文档是否包括这个字段，索引中每个文档的每个 text 类型的字段 大约占用 1 个 byte 的空间。
  
  对于 not_analyzed 字符串字段的归一值默认是禁用的，

### 4）BM25

k1 和 b 的默认值适用于绝大多数文档集合，但最优值还是会因为文档集不同而有所区别，为了找到文档集合的最优值，就必须对参数进行反复修改验证。


整体而言就是对 TF-IDF 算法的改进，对于 TF-IDF 算法，TF(t) 部分的值越大，整个公式返回的值就会越大，

BM25 针对针对这点进行来优化，随着TF(t) 的逐步加大，该算法的返回值会趋于一个数值。

- 有一个比较好的特性就是它提供了两个可调参数
- k1

  这个参数控制着词频结果在词频饱和度中的上升速度。默认值为 1.2 。值越小饱和度变化越快，值越大饱和度变化越慢。

- b

  这个参数控制着字段长归一值所起的作用， 0.0 会禁用归一化， 1.0 会启用完全归一化。默认值为 0.75 。

### 总结

- TF-IDF 的组合使用

  以上三个因素——词频（term frequency）、逆向文档频率（inverse document frequency）和字段长度归一值（field-length norm）——是在索引时计算并存储的。最后将它们结合在一起计算单个词在特定文档中的 权重 。

- TF-IDF 实用评分函数

  score(q,d)  =  
              queryNorm(q)  
            · coord(q,d)    
            · ∑ (           
                  tf(t in d)   
                · idf(t)²      
                · t.getBoost() 
                · norm(t,d)    
              ) (t in q)  
  
  
  
  score(q,d) 是文档 d 与查询 q 的相关度评分。
  
  
  queryNorm(q) 是 查询归一化 因子 （新）。
  
  
  coord(q,d) 是 协调 因子 （新）。
  
  
  查询 q 中每个词 t 对于文档 d 的权重和。
  
  
  tf(t in d) 是词 t 在文档 d 中的 词频 。
  
  
  idf(t) 是词 t 的 逆向文档频率 。
  
  
  t.getBoost() 是查询中使用的 boost（新）。
  
  
  norm(t,d) 是 字段长度归一值 ，与 索引时字段层 boost （如果存在）的和（新）。

- BM25 的函数

## 3、explain 

###  查看搜索相关性分数的计算过程

### 导入测试数据

PUT /blogs_index
{
  "settings": {
    "index": {
      "number_of_shards": 1,
      "number_of_replicas": 1
    }
  },
  "mappings": {
    "_doc": {
      "dynamic": false,
      "properties": {
        "id": {
          "type": "integer"
        },
        "author": {
          "type": "keyword"
        },
        "title": {
          "type": "text",
          "analyzer": "ik_smart"
        },
        "content": {
          "type": "text",
          "analyzer": "ik_max_word",
          "search_analyzer": "ik_smart"
        },
        "tag": {
          "type": "keyword"
        },
        "influence": {
          "type": "integer_range"
        },
        "createAt": {
          "type": "date",
          "format": "yyyy-MM-dd HH:mm"
        }
      }
    }
  }
}

POST _bulk
{"index":{"_index":"blogs_index","_type":"_doc","_id":"1"}}
{"id":1,"author":"方才兄","title":"es的相关度","content":"这是关于es的相关度的文章","tag":[1,2,3],"influence":{"gte":10,"lte":12},"createAt":"2020-05-24 10:56"}
{"index":{"_index":"blogs_index","_type":"_doc","_id":"2"}}
{"id":2,"author":"方才兄","title":"相关度","content":"这是关于相关度的文章","tag":[2,3,4],"influence":{"gte":12,"lte":15},"createAt":"2020-05-23 10:56"}
{"index":{"_index":"blogs_index","_type":"_doc","_id":"3"}}
{"id":3,"author":"方才兄","title":"es","content":"这是关于关于es和编程的必看文章","tag":[2,3,4],"influence":{"gte":12,"lte":15},"createAt":"2020-05-22 10:56"}
{"index":{"_index":"blogs_index","_type":"_doc","_id":"4"}}
{"id":4,"author":"方才","title":"关注我，系统学习es","content":"这是关于es的文章，介绍了一点相关度的知识","tag":[1,2,3],"influence":{"gte":10,"lte":15},"createAt":"2020-05-24 10:56"}

### DSL示例

GET /blogs_index/_search
{
  "query": {
    "match": {
      "title": "es的相关度"
    }
  },
  "explain": true
}

Token【es】的相关性评分：

"_explanation": {
          "value": 2.593309,
          "description": "sum of:",
          "details": [
            {
              "value": 0.31387395,
              "description": "weight(title:es in 0) [PerFieldSimilarity], result of:",
              "details": [
                {
                  "value": 0.31387395,
                  "description": "score(doc=0,freq=1.0 = termFreq=1.0\n), product of:",
                  "details": [
                    {
                      "value": 0.35667494,
                      "description": "idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:",
                      "details": [
                        {
                          "value": 3,
                          "description": "docFreq",
                          "details": []
                        },
                        {
                          "value": 4,
                          "description": "docCount",
                          "details": []
                        }
                      ]
                    },
                    {
                      "value": 0.88,
                      "description": "tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:",
                      "details": [
                        {
                          "value": 1,
                          "description": "termFreq=1.0",
                          "details": []
                        },
                        {
                          "value": 1.2,
                          "description": "parameter k1",
                          "details": []
                        },
                        {
                          "value": 0.75,
                          "description": "parameter b",
                          "details": []
                        },
                        {
                          "value": 3,
                          "description": "avgFieldLength",
                          "details": []
                        },
                        {
                          "value": 4,
                          "description": "fieldLength",
                          "details": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }

## 4、相关度控制

### 1）boost  参数

- 范围

	- boost>1 相关度相对性提升
	- 0<boost<1，相对性降低
	- boost<0，贡献负分

- 这种提升或降低并不一定是线性的

  新的评分 _score 会在应用权重提升之后被 归一化 ，每种类型的查询都有自己的归一算法

- DSL 示例

  GET /blogs_index/_search
  {
    "query": {
      "bool": {
        "must": [
          {
            "match": {
              "title": {
                "query": "es",
                "boost": 2
              }
            }
          },
          {
            "match": {
              "content": "es"
            }
          }
        ]
      }
    },
    "explain": true
  }
  
  根据结果，我们可以看到：对应文档的_score = BM25（es in title） + BM25（es in content）；其中  BM25（es in title）= boost*idf*tfNorm

	- 结果图

- boost 可用于任何查询语句

### 2）查询方式改变

-  constant_score query

	- 嵌套一个 filter 查询，为任意一个匹配的文档指定评分为 boost 的参数值【默认值为1】 ，忽略 TF-IDF 信息。
	- DSL 示例

	  GET /blogs_index/_search
	  {
	      "query": {
	          "constant_score" : {
	              "filter" : {
	                  "term" : { "title": "es"}
	              },
	              "boost" : 1.2
	          }
	      }
	  }
	  
	  GET /blogs_index/_search
	  {
	    "query": {
	      "bool": {
	        "should": [
	          { "constant_score": {
	            "filter": { "match": { "title": "es"}}
	          }},
	          { "constant_score": {
	            "boost":   2 ,
	            "filter": { "match": { "title": "相关度"}}
	          }}
	        ]
	      }
	    }
	  }

- function_score query 

  https://www.elastic.co/guide/en/elasticsearch/reference/6.8/query-dsl-function-score-query.html
  
  
  允许为每个与主查询匹配的文档应用一个函数，以达到改变甚至完全替换原始查询评分 _score 的目的。
  
  实际上，也能用过滤器对结果的 子集 应用不同的函数，这样一箭双雕：既能高效评分，又能利用过滤器缓存。

	- 允许我们修改通过 query 检索出来的文档的分数
	- 必须定义​​一个查询和一个或多个函数，这些函数为查询返回的每个文档计算一个新分数
	- 5种得分函数

		- weight

		  为每个文档应用一个简单而不被规范化的权重提升值：当 weight 为 2 时，最终结果为 2 * _score 。
		  
		  GET /_search
		  {
		      "query": {
		          "function_score": {
		            "query": { "match_all": {} },
		            "boost": "5", 
		            "functions": [
		                {
		                    "filter": { "match": { "test": "bar" } },
		                    "random_score": {}, 
		                    "weight": 23
		                },
		                {
		                    "filter": { "match": { "test": "cat" } },
		                    "weight": 42
		                }
		            ]
		  
		          }
		      }
		  }

		- field_value_factor

		  使用这个值来修改 _score ，如将 popularity 或 votes （受欢迎或赞）作为考虑因素。
		  
		  PUT /blogposts/post/1
		  {
		    "title":   "About popularity",
		    "content": "In this post we will talk about...",
		    "votes":   6
		  }
		  
		  
		  

			- field

				- 要从文档中提取的字段

			- modifier

			  种融入受欢迎度更好方式是用 modifier 平滑 votes 的值。换句话说，我们希望最开始的一些赞更重要，但是其重要性会随着数字的增加而降低。 0 个赞与 1 个赞的区别应该比 10 个赞与 11 个赞的区别大很多。
			  
			  对于上述情况，典型的 modifier 应用是使用 log1p 参数值，公式如下：
			  
			  new_score = old_score * log(1 + number_of_votes)
			  
			  
			  修饰语 modifier 的值可以为： none （默认状态）、 log 、 log1p 、 log2p 、 ln 、 ln1p 、 ln2p 、 square 、 sqrt 以及 reciprocal 

				- DSL

				  GET /blogposts/post/_search
				  {
				    "query": {
				      "function_score": {
				        "query": {
				          "multi_match": {
				            "query":    "popularity",
				            "fields": [ "title", "content" ]
				          }
				        },
				        "field_value_factor": {
				          "field":    "votes",
				          "modifier": "log1p" 
				        }
				      }
				    }
				  }
				  
				  修饰语 modifier 的值可以为： none （默认状态）、 log 、 log1p 、 log2p 、 ln 、 ln1p 、 ln2p 、 square 、 sqrt 以及 reciprocal 

			- factor

				- 字段值乘以的可选因子，默认为1。

			- DSL 示例

			  GET /blogposts/post/_search
			  {
			    "query": {
			      "function_score": { 
			        "query": { 
			          "multi_match": {
			            "query":    "popularity",
			            "fields": [ "title", "content" ]
			          }
			        },
			        "field_value_factor": { 
			          "field": "votes" ,
			   		"factor": 1.2,
			            "modifier": "sqrt",
			             "missing": 1
			        }
			      }
			    }
			  }
			  每个文档的最终评分 _score 都做了如下修改：
			  
			  new_score = old_score * number_of_votes
			  
			  将转化为以下得分公式：
			  sqrt(1.2 * doc['votes'].value)
			  	
			  
			  function_score 查询将主查询和函数包括在内。
			  
			  主查询优先执行。
			  
			  field_value_factor 函数会被应用到每个与主 query 匹配的文档。
			  
			  
			  每个文档的 votes 字段都 必须 有值供 function_score 计算。如果 没有 文档的 votes 字段有值，那么就 必须 使用 missing 属性 提供的默认值来进行评分计算。
			  
			  

				- 问题

				  然而这并不会带来出人意料的好结果，全文评分 _score 通常处于 0 到 10 之间，如下图 Figure 29, “受欢迎度的线性关系基于 _score 的原始值 2.0” 中，有 10 个赞的博客会掩盖掉全文评分，而 0 个赞的博客的评分会被置为 0 。
				  
				  

		- random_score

		  为每个用户都使用一个不同的随机评分对结果排序，但对某一具体用户来说，看到的顺序始终是一致的。
		  
		  GET /_search
		  {
		      "query": {
		          "function_score": {
		              "random_score": {
		                  "seed": 10,
		                  "field": "_seq_no"
		              }
		          }
		      }
		  }

		- 衰减函数

		  https://www.elastic.co/guide/en/elasticsearch/reference/6.8/query-dsl-function-score-query.html

			- DSL示例

			  "DECAY_FUNCTION": { 
			      "FIELD_NAME": { 
			            "origin": "11, 12",
			            "scale": "2km",
			            "offset": "0km",
			            "decay": 0.33
			      }
			  }
			  
			  
			  
			  

			- 3种DECAY_FUNCTION 

				- gauss

					- 正常衰减

				- exp

					- 指数衰减

				- linear

					- 线性衰减

			- Field

				- 必须是数字，日期或地理点字段。
				- 对于多值字段【Array】

					- multi_value_mode

					  
					  min
					  距离是最小距离
					  
					  max
					  距离是最大距离
					  
					  avg
					  距离是平均距离
					  
					  sum
					  距离是所有距离的总和

			- origin

				- 用于计算距离的原点

			- scale

				- 定义到原点的距离+偏移

			- offset

				- 衰减函数将仅计算距离大于 offset 文档的衰减函数。默认值为0。

			- decay

				- 如何在 scale 给定的距离处对文档进行评分
				- 如果decay未定义，则 scale 处文档得分为0.5。

		- script_score

		  如果需求超出以上范围时，用自定义脚本可以完全控制评分计算，实现所需逻辑。
		  
		  GET /_search
		  {
		      "query": {
		          "function_score": {
		              "query": {
		                  "match": { "message": "elasticsearch" }
		              },
		              "script_score" : {
		                  "script" : {
		                    "source": "Math.log(2 + doc['likes'].value)"
		                  }
		              }
		          }
		      }
		  }
		  
		  分数必须为非负数。否则，Elasticsearch返回错误。

	- score_mode

	  参数 score_mode 指定如何组合计算出的分数：
	  
	  multiply  分数相乘（默认）
	  
	  sum  分数相加
	  
	  avg  分数是平均值
	  
	  first   具有匹配过滤器的第一个函数被应用
	  
	  max  使用最高分
	  
	  min  使用最低分数

	- boost_mode

	  新计算的分数与查询分数合并。该参数boost_mode定义如何：
	  
	  multiply
	  查询分数和功能分数相乘（默认）
	  
	  replace
	  仅使用功能分数，查询分数将被忽略
	  
	  sum
	  查询分数和功能分数相加
	  
	  avg
	  平均
	  
	  max
	  查询分数和功能分数的最大值
	  
	  min
	  查询分数和功能分数的最小值

	- max_boost

		- 将新分数限制为不超过特定限制

	- min_score

		- 文档所需分数阈值，排除不符合特定分数阈值的文档
		- 需要对查询返回的所有文档进行打分，然后一一过滤掉。

	- DSL 综合示例

	  GET /blogs_index/_search
	  {
	    "query": {
	      "function_score": {
	        "query": {
	          "match_all": {}
	        },
	        "boost": "5",
	        "functions": [
	          {
	            "filter": {
	              "match": {
	                "title": "es"
	              }
	            },
	            "random_score": {},
	            "weight": 23
	          },
	          {
	            "filter": {
	              "match": {
	                "title": "相关度"
	              }
	            },
	            "weight": 42
	          }
	        ],
	        "max_boost": 42,
	        "score_mode": "max",
	        "boost_mode": "multiply",
	        "min_score": 10
	      }
	    },
	    "explain": true
	  }
	  
	  

- dis_max query

	- dis_max查询使用单个最佳匹配查询子句的分数。
	- tie_breaker

	  通过参数 tie_breaker 【默认值为0】 控制其他查询子句的分数对 _score 的影响。
	  
	  相关性得分计算公式：
	  
	  _score = max(BM25) + ∑ other(BM25)*tie_breaker 

	- DSL示例

	  GET /_search
	  {
	      "query": {
	          "dis_max" : {
	              "tie_breaker" : 0.7,
	              "boost" : 1.2,
	              "queries" : [
	                  {
	                      "term" : { "age" : 34 }
	                  },
	                  {
	                      "term" : { "age" : 35 }
	                  }
	              ]
	          }
	      }
	  }

- boosting query

  https://www.elastic.co/guide/en/elasticsearch/reference/6.4/query-dsl-boosting-query.html
  
  该boosting查询可用于有效降级与给定查询匹配的结果。与布尔查询中的“ NOT”子句不同的是，它仍会选择包含不良词的文档，但会降低其总体得分
  

	- positive

		- 用于获取返回结果

	- negative

		- 对上述结果的相关性打分进行调整

	- negative_boost

		- 调整参数：升权(>1), 降权(>0 and <1)

	- DSL示例

	  GET /_search
	  {
	      "query": {
	          "boosting" : {
	              "positive" : {
	                  "term" : {
	                      "field1" : "value1"
	                  }
	              },
	              "negative" : {
	                   "term" : {
	                       "field2" : "value2"
	                  }
	              },
	              "negative_boost" : 0.2
	          }
	      }
	  }
	  
	  它接受 positive 和 negative 查询。只有那些匹配 positive 查询的文档罗列出来，对于那些同时还匹配 negative 查询的文档将通过文档的原始 _score 与 negative_boost 相乘的方式降级后的结果。
	  
	  为了达到效果， negative_boost 的值必须小于 1.0 。在这个示例中，所有包含负向词的文档评分 _score 都会减半。
	  
	  

### 3）rescore 结果集重新评分

一个简单的 match 查询已经通过排序把包含所有含有搜索词条的文档放在结果列表的前面了。事实上，我们只想对这些 顶部文档 重新排序，来给同时匹配了短语查询的文档一个额外的相关度升级。

- 先query，再 rescore 重新评分

  
  window_size 是每一分片进行重新评分的顶部文档数量。
  
  
  query 目前唯一支持的重新打分算法
  
  GET /blogs_index/_search
  {
    "query": {
      "bool": {
        "should": [
          {
            "match": {
              "content": {
                "query": "es的相关度",
                "minimum_should_match": "30%"
              }
            }
          },
          {
            "match": {
              "title": {
                "query": "es"
              }
            }
          }
        ]
      }
    },
    "rescore": {
      "window_size": 3,
      "query": {
        "rescore_query": {
          "match_phrase": {
            "content": {
              "query": "es的相关度",
              "slop": 50
            }
          }
        }
      }
    }
  }

### 4）更改BM25 参数 k1 和 b 的值

只能在创建index的时候定义字段的similarity ，在后续，可以通过关闭索引，更新索引设置，开启索引这个过程进行更新 my_bm25 的 参数值。这样可以无须重建索引又能试验不同的相似度算法配置。

PUT /my_index
{
  "settings": {
    "similarity": {
      "my_bm25": {
        "type": "BM25",
        "b": 0.8,
        "k1": 1.5
      }
    }
  },
  "mappings": {
    "doc": {
      "properties": {
        "title": {
          "type": "text",
          "similarity": "my_bm25"
        }
      }
    }
  }
}

## 5、被破坏的相关度

### 分布式存储和分布式查询造成的

### 每个分片会根据 该分片 内的所有文档计算一个本地 IDF

因为文档是均匀分布存储的，两个分片的 IDF 是相同的。相反，设想如果有 5 个 foo 文档存于分片 1 ，而第 6 个文档存于分片 2 ，在这种场景下， foo 在一个分片里非常普通（所以不那么重要），但是在另一个分片里非常出现很少（所以会显得更重要）。这些 IDF 之间的差异会导致不正确的结果。


在实际应用中，这并不是一个问题，本地和全局的 IDF 的差异会随着索引里文档数的增多渐渐消失，在真实世界的数据量下，局部的 IDF 会被迅速均化，所以上述问题并不是相关度被破坏所导致的，而是由于数据太少。

### 两种方式解决

- 只在主分片上创建索引
- 搜索的URL 中指定参数 “_search?search_type=dfs_query_then_fetch”

  dfs 是指 分布式频率搜索
  （Distributed Frequency Search） ， 它告诉 Elasticsearch ，先分别获得每个分片本地的 IDF ，然后根据结果再计算整个索引的全局 IDF 。
  
  
  不要在生产环境上使用 dfs_query_then_fetch 。完全没有必要。只要有足够的数据就能保证词频是均匀分布的。没有理由给每个查询额外加上 DFS 这步。

## 6、相关度控制最后要做的事情

1、理解评分过程是非常重要的，这样就可以根据具体的业务对评分结果进行调试、调节、减弱和定制。

2、本文介绍的4种相关度控制方案，建议结合实践，根据自己的业务需求，多动手调试练习。

3、最相关 这个概念是一个难以触及的模糊目标，通常不同人对文档排序又有着不同的想法，这很容易使人陷入持续反复调整而没有明显进展的怪圈。强烈建议不要去追求最相关，而要监控测量搜索结果。

4、评价搜索结果与用户之间相关程度的指标。如果查询能返回高相关的文档，用户会选择前五中的一个，得到想要的结果，然后离开。不相关的结果会让用户来回点击并尝试新的搜索条件。

5、要想物尽其用并将搜索结果提高到 极高的 水平，唯一途径就是需要具备能评价度量用户行为的强大能力。

