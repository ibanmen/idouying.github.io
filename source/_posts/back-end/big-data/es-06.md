---
title: 重学 Elastic Stack 之 Elasticsearch 深入了解(二)
date: 2021-02-08 22:10:00
categories: BigData
tags:
  - Elastic Stack
  - ES
---

深入了解 ES 集群、分页、聚合分析、父子文档、数据建模等。

<!--more-->

## 集群分布式模型与选主与脑裂问题

### 分布式特性

- ES 的分布式架构带来的好处
  - 储存的水平扩容，支持 PB 级数据
  - 提高系统的可用性，部分节点停止服务，整个集群的服务不受影响
- ES 的分布式架构
  - 不同的集群通过不同的名字来区分，默认名字 “elasticsearch”
  - 通过配置文件的修改，或者在命令行中 `-E cluster.name=xxx` 设定

### 节点

- 节点是一个 ES 的实例
  - 其本质就是一个 JAVA 进程
  - 一台机器可以运行多个 ES 进程，但是生产环境一般建议一台机器就运行一个 ES 实例
- 每一个节点都有名字，通过配置文件配置，或者启动时候 `-E node.name=xxx` 指定
- 每一个节点在启动之后，都会分配一个 UID，保存在 data 目录下

### Coordinating Node

- 处理请求的节点，叫 Coordinating Node
  - 路由请求到正确的节点，例如创建索引的请求，需要路由到 Master 节点
- 所有节点默认都是 Coordinating Node
- 通过将其他类型设置成 False ，使其成为 Dedicated Coordinating Node

### Data Node

- 可以保存数据的节点，叫做 Data Node
  - 节点启动后，默认就是数据节点。可以设置 `node.data:false` 禁止
- Data Node 的职责
  - 保存分片数据。在数据扩展上起到了至关重要的作用（由 Master Node 决定把分片分发到数据节点上）
- 通过增加数据节点
  - 可以解决数据**水平扩展**和解决**数据单点**的问题

### Master Node

- Master Node 的职责
  - 处理创建，删除索引等请求 / 决定分片被分配到哪个节点 / 负责索引的创建与删除
  - 维护并且更新 Cluster State
- Master Node 的最佳实践
  - Master 节点非常重要，在部署上需要考虑解决单点的问题
  - 为一个集群设置多个 Master 节点 / 每个节点值承担 Master 的单一角色

### Master Eligible Nodes & 选主流程

- 一个集群，支持配置多个 Master Eligble 节点。这些节点可以在必要时（如 Master 节点出现故障，网络故障时）参与选主流程，成为 Master 节点
- 每个节点启动后，默认就是一个 Master eligible 节点
  - 可以设置 `node.master:false`
- 当集群内的第一个 Master eligible 节点启动的时候，它会将自己选举成 Master 节点

### 集群状态

- 集群状态信息（Cluster State），维护了一个集群中，必要的信息
  - 所有的节点信息
  - 所有的索引和其相关的 Mapping 与 Setting 信息
  - 分片的路由信息
- 在每个节点都保存了集群的状态信息
- 但是，只有 Master 节点才能修改集群的状态信息，并负责同步给其他节点
  - 因为，任意节点都能修改信息会导致 Cluster State 信息不一致

### Master Eligbile Nodes & 选主的过程

- 互相 ping 对方。**Node Id** 低的会被成为被选举的节点
- 其他节点会加入集群，但是不承担 Master 节点的角色。一旦发现被选中的主节点丢失，就会选举出新的 Master 节点

![1][1]

### 脑裂问题

- Split-Brain ，分布式系统的经典网络问题，当出现网络问题，一个节点和其他节点无法连接
  - Node 2 和 Node 3 会被重新选举 Master
  - Node 1 自己还是作为 Master，组成一个集群，同时更新 Cluster State
  - 导致 2 个 master，维护不同的 cluster state。当网络恢复是，无法选择正确恢复

![2][2]

### 如何避免脑裂问题

- 限定一个选举条件，这是 quorum（仲裁），只有在 Master eligble 节点数大于 quorum 时，才能进行选举
  - Quorum = (master 节点总数 / 2) + 1
  - 当 3 个 master eligible 时，设置 **discovery.zen.minimum_master_nodes** 为 2 ，即可避免脑裂
- 从 7.0 开始，无需这个配置
  - 移除 minimum_master_nodes 参数，让 ES 自己选择可以形成冲裁的节点
  - 典型的主节点选举现在只需要很短的时间可以完成。集群的伸缩变得更加安全，更容易，并且可能造成丢失数据的系统配置选项更少了
  - 节点更清楚的记录它们的状态，有助于诊断为什么它们不能加入集群或为什么无法选举除主节点

### 为什么高可用是奇数节点？

为了避免脑裂，同时也为了避免浪费资源（机器），Raft 算法为：

N 为 master 节点总数，可容忍 **(N-1)/2** 失败数，quorum 需要 **(N/2)+1**

### 分布式共识算法

一致性往往指分布式系统中多个副本对外呈现的数据的状态。共识则描述了分布式系统中多个节点之间，彼此对某个状态达成一致结果的过程。因此，一致性描述的是结果状态，共识则是一种手段。达成某种共识并不意味着就保障了一致性。

对于分布式系统来讲，各个节点通常都是相同的确定性状态机模型（又称为状态机复制问题，state-machine replication），从相同初始状态开始接收相同顺序的指令，则可以保证相同的结果状态。因此，系统中多个节点最关键的是对多个事件的顺序进行共识，即排序。

**问题与挑战**

一般地，把出现故障（crash或fail-stop，即不响应）但不会伪造信息的情况称为“非拜占庭错误”（non-byzantine fault）或“故障错误”（Crash Fault）；伪造信息恶意响应的情况称为“拜占庭错误”（Byzantine Fault），对应节点为拜占庭节点。

**常见算法**

根据解决的是非拜占庭的普通错误情况还是拜占庭错误情况，共识算法可以分为Crash Fault Tolerance（CFT）类算法和Byzantine Fault Tolerance（BFT）类算法。

对于非拜占庭错误：已经存在一些经典的解决算法，包括Paxos、Raft及其变种等。这类容错算法往往性能比较好，处理较快，容忍不超过一半的故障节点。

对于拜占庭错误：一般包括PBFT（Practical Byzantine Fault Tolerance）为代表的确定性系列算法、PoW为代表的概率算法等。对于确定性算法，一旦达成对某个结果的共识就不可逆转，即共识是最终结果；而对于概率类算法，共识结果则是临时的，随着时间推移或某种强化，共识结果被推翻的概率越来越小，成为事实上的最终结果。拜占庭类容错算法往往性能较差，容忍不超过1/3的故障节点。

此外，XFT（Cross Fault Tolerance）等改进算法可以提供类似CFT的处理响应速度，并能在大多数节点正常工作时提供BFT保障。

crash fault tolerance 的系统，节点数需要满足 n=2f+1 （ f 为会崩溃的节点数），所以最小的系统需要 3 个节点。

拜占庭容错系统的节点数是 n=3f+1 （ f 为拜占庭节点数量）。所以拜占庭容错系统需要至少 4 个节点才能容忍 1 个拜占庭节点。

相关的理论可以看 Paxos，Raft，pbft 等著名论文。主要思想是：保证正常运作的节点数量过系统的半数（过半机制）。

- [FLP 不可能定理](https://www.the-paper-trail.org/post/2008-08-13-a-brief-tour-of-flp-impossibility/)
- [Raft 共识算法论文](https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf)

### 配置节点类型

- 一个节点默认下是一个 Master eligible ，data and ingest node

| 节点类型          | 配置参数    | 默认值                      |
| :---------------- | :---------- | :-------------------------- |
| maste eligible    | node.master | true                        |
| data              | node.data   | true                        |
| ingest            | node.ingest | ture                        |
| coordinating only | ⽆           | 设置上⾯三个参数全部为 false |
| machine learning  | node.ml     | true (需要 enable x-pack)   |

> 配置版本基于 7.1，相关配置可能已发生改动详情看 [官网](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html)

## 分片与集群的故障转移

### Primary Shard - 提升系统存储容量

- 分片是 ES 分布式储存的基石
  - 主分片 / 副本分片
- 通过主分片，将数据分布在所有节点上
  - Primary Shard , 可以将一份索引的数据，分散在多个 Data Node 上，实现储存的水平扩展
  - 主分片（Primary Shard）数在索引创建时候指定，后续默认不能修改，如要修改，需重建索引

### Replica Shard - 提高数据可用性

- 数据可用性
  - 通过引入副本分片（Replica Shard）提高数据的可用性。一旦主分片丢失，副本分片可以在 Promote 成主分片。副本分片数可以动态调整的。每个节点上都有完备的数据。如果不设置副本分片，一旦出现节点硬件故障，就有可能造成数据丢失。
- 提高系统的读取性能
  - 副本分片由主分片（Primary Shard）同步。通过支持增加 Replica 个数，一定程度可以提高读取的吞吐量

### 分片数的设置

- 如何规划一个索引的主分片数和副本分片数
  - 主分片数过小：例如创建一个 1 个 Primary Shard 的 index
    - 如果该索引增长很快，集群无法通过增加节点实现对这个索引的数据扩展
  - 主分片数设置过大：导致单个 Shard 容量很小，引发一个节点上有过多分片，影响性能
  - 副本分片设置过多，会降低集群整体的写入性能

### 单节点集群

- 副本无法分片，集群状态为黄色

![3][3]

> 使用 cerebro 观察集群状态 https://github.com/lmenezes/cerebro

### 增加一个数据节点

- 集群状态转为绿色
- 集群具备故障转移能力
- 尝试着将 Replica 设置成 2 和 3，查看集群的状况

![4][4]

### 在增加一个节点

- 集群具备故障转移能力
- Master 节点会决定分片分配到哪个节点
- 通过增加节点数，提高集群的计算能力

![5][5]

### 故障转移

- 3 个节点共同组成。包含 1 个索引，索引设置了 3 个 Primary Shard 和 1 个 Replica
- 节点 1 是 Master 节点，节点意外出现故障。集群重新选举 Master 节点
- Node3 上的 R0 提升成 P0 ，集群变黄
- R0 和 R1 分配，集群变绿

![6][6]

### 集群健康状态

- Green : 健康状态，所有的主分片和副本分片都可用
- Yellow: 亚健康，所有的主分片可用，部分副本分片不可用
- Red：不健康状态，部分主分片不可用

```json
GET /_cluster/health
```

**Demo**

- 启动一个节点，3 个 Primary shard，1 个 Replica，集群黄色，因为无法分片 Replica
- 启动 3 个节点，1 个索引上包含 3 个 Primary Shard，一个 Replica
- 关闭 Node 1（Master）
- 查看 Master Node 重新选举
- 集群变黄，然后重新分配

**小结**

- 主分片，副本分片的作用
  - 主分片的分片数，设置后不能修改，除非重新索引数据
  - 副本分片可以随时修改
- 集群的故障转移
  - 需要集群具备故障转移的能力，必须将索引的副本分片数设置为1，否则，一点有节点就是，就会造成数据丢失

## 文档分布式存储

### 文档储存在分片上

- 文档会存储在具体的某个主分片和副本分片上：例如文档 1，会储存在 P0 和 R0 分片上
- 文档到分片的映射算法
  - 确保文档能均匀分布在所用分片上，充分利用硬件资源，避免部分机器空闲，部门机器繁忙
  - 潜在的算法
    - 随机 / Round Robin. 当查询文档 1，分片数很多，需要多次查询才能查档文档 1
    - 维护文档到分片的映射关系，当文档数据量大的时候，维护成本高
    - 实时计算，通过文档 1，自动算出，需要去哪个分片上获取文档

### 文档到分片的路由算法

- shard = hash(_routing) % number_of_primary_shards
  - Hash 算法确保文档均匀分散到分片中
  - 默认的_routing 值是文档 id
  - 可以自行制定 routing 数值，例如用相同国家的商品，都分配到制定的 shard
  - 设置 Index Setting 后，**Primary 数，不能随意修改的根本原因**

```json
PUT posts/_doc/100?routing=bigdata
{
  "title": "Mastering Elasticsearch",
  "body": "Let's Rock"
}
```

### 更新文档

- 顺序：index -> hash -> route -> delete -> index -> success -> response

![7][7]

### 删除一个文档

- 顺序 ：detele -> hash&route -> delete -> delete replica -> success -> deleted -> response

![8][8]

**小结**

- 可以设置 Index Settings ，控制数据的分片
- Primary Shard 的值不能修改，修改需要重新 Index。默认值是 5，从版本 7 开始，默认值为 1
- 索引写入数据后，Replica 值可以修改。增加副本，可提高大并发下的读取性能
- 通过控制集群的节点数，设置 Primary Shard 数，实现水平扩展

## 分片及其生命周期

### 分片的内部原理

- 什么是 ES 的分片
  - ES 中最小的工作单元 / 是一个 Lucence 的 Index
- 一些问题：
  - 为什么 ES 的搜索时近实时的（1 秒后被搜到）
  - ES 如何保证在断电时数据也不会丢失
  - 为什么删除文档，并不会立刻释放空间

### 倒排索引的不可变性

- 倒排索引采用 Immutable Design, 一旦生成，不可更改
- 不可变性，带来了的好处如下：
  - 无需考虑并发写文件的问题，避免了锁机制带来的性能问题
  - 一旦读入内核的文件系统缓存，便留在那里，只要文件系统存有足够的空间，大部分请求就会直接请求内存，不会命中磁盘，提高了很大的性能
  - 缓存容易生成和维护 / 数据可以被压缩
- 不可变更性，带来了的挑战：如果需要让一个新的文档可以被搜索，需要重建整个索引

### Lucence index

- 在 Lucene 中，单个倒排索引文件被称为 Segment。Segment 是自包含的，不可变更的。多个 Segments 汇总在一起，称为 Lucene 的 Index，其对应的就是 ES 中的 Shard
- 当有新文档写入时，会生成新的 Segment, 查询时会同时查询所有的 Segments，并且对结果汇总。Luncene 中有个文件，用来记录所有的 Segments 的信息，叫做 Commit Point
- 删除的文档信息，保存在”.del” 文件中

![9][9]

### Refresh

- 将 Index buffer 写入 Segment 的过程叫做 Refresh。Refresh 不执行 fsync 操作
- Refresh 频率：默认 1 秒发生一次，可通过 index.refresh_interval 配置。Refresh 后，数据就可以被搜索到了。这也就是为什么 ES 被称为近实时搜索
- 如果系统有大量的数据写入，那就会产生很多的 Segment
- Index Buffer 被占满时，会触发 Refresh, 默认值是 JVM 的 10%

![10][10]

### Transaction Log

- Segment 写入磁盘的过程相对耗时，借助文件系统缓存，Refresh 时，先将 Segment 写入缓存以开放查询
- 蔚来保证数据不会丢失。所有在 Index 文档时，同时写 Transaction Log，高版本开始，Transaction Log 默认落盘。每个分片都有一个 Transaction Log
- 当 ES Refresh 时，Index Buffer 被清空，Transaction Log 不会清空

![11][11]

### Flush

- ES Flush & Lucene Commit
  - 调用 Refresh ，Index Buffer 清空并且 Refresh
  - 调用 fsync, 将缓存中的 Segments 写入磁盘
  - 清空（删除）Transaction Log
  - 默认 30 分钟调用一次
  - Transaction Log 满（默认 512M）

![12][12]

### Merge

- Segment 很多，需要定期被合并
  - 减少 Segments / 删除已经删除的文档
- ES 和 Lucene 会自动进行 Merge 操作
  - POST my_index/_forcemerge

## 剖析分布式查询及相关性算法

### 分布式搜索的运行机制

- ES 的搜索，会分两阶段进行
  - 第一阶段 - Query
  - 第二阶段 - Fetch
- Query-then-Fetch

### Query 阶段

- 用户发出搜索请求到 ES 节点。节点收到请求后，会以 Coordinating 节点的身份，在 6 个主副分片中随机选择 3 个分片，发送查询请求
- 被选中的分片执行查询，进行排序。然后，每个分片都会返回 From + Size 个排序后的文档 Id 和排序值给 Coordinating 节点

![13][13]

### Fetch 阶段

- Coordinating Node 会将 Query 阶段，从每个分片获取的排序后的文档 Id 列表，重新进行排序。选取 From 到 From + Size 个文档的 Id
- 以 multi get 请求的方式，到相应的分片获取详细的文档数据

### Query Then Fetch 潜在的问题

- 性能问题
  - 每个分片上需要查的文档个数 = from + size
  - 最终协调节点需要处理：number_of_shard * (from + size)
  - 深度分页 (可以使用 Search After)
- 相关性算分
  - 每个分片都基于自己的分片上的数据进行相关度计算。这会导致打分偏离的情况，特别是数据量很少时。相关性算分在分片之间是相互独立。当文档总数很少的情况下，如果主分片大于 1，主分片越多，相关性算分会越不准。

### 解决算分不准的方法

- 数据量不大的时候，可以将主分片数设置为 1
  - 当数据量足够大时候，只要保证文档均匀分散在各个分片上，结果一般就不会出现偏差
- 使用 DFS Query Then Fetch
  - 搜索的 URL 中指定参数 “_search?search_type=dfs_query_then_fetch”
  - 到每个分片把各分片的词频和文档频率进行搜集，然后完整的进行一次相关性算分，消耗更加多的 CPU 和内存，执行性能低下，一般不建议使用

### 相关性算分问题 Demo

- 写入 3 条记录 “Good” / “Good moring” / “good morning everyone”
- 使用 1 个主分片测试，Good 应该排在第一，Good DF 数值应该是 3
- 和 20 个主分片测试
- 当多个主分片时，3 个文档的算分都一样。可以通过 Explain API 进行分析
- 在 3 个主分片上执行 DFS Query Then Fetch ，结果和一个分片上一致

```json
DELETE message
PUT message
{
  "settings": {
    "number_of_shards": 20
  }
}
GET message
POST message/_doc?routing=1
{
  "content":"good"
}
POST message/_doc?routing=2
{
  "content":"good morning"
}
POST message/_doc?routing=3
{
  "content":"good morning everyone"
}
POST message/_search
{
  "explain": true,
  "query": {
    "match_all": {}
  }
}

POST message/_search
{
  "explain": true,
  "query": {
    "term": {
      "content": {
        "value": "good"
      }
    }
  }
}

POST message/_search?search_type=dfs_query_then_fetch
{
  "query": {
    "term": {
      "content": {
        "value": "good"
      }
    }
  }
}
```

## 排序及 Doc Values & Field Data

## 排序

- ES 默认采用相关性算分对结果进行降序排序
- 可以通过设置 sorting 参数，自行设定排序
- 如果不指定 _score, 算分为 null

```json
POST /kibana_sample_data_ecommerce/_search
{
  "size": 5,
  "query": {
    "match_all": {

    }
  },
  "sort": [
    {"order_date": {"order": "desc"}}
  ]
}
```

### 多字段进行排序

- 组合多个条件
- 优先考虑写在前面的排序
- 支持对相关性算分进行排序

```json
POST /kibana_sample_data_ecommerce/_search
{
  "size": 5,
  "query": {
    "match_all": {

    }
  },
  "sort": [
    {"order_date": {"order": "desc"}},
    {"_doc":{"order": "asc"}},
    {"_score":{ "order": "desc"}}
  ]
}
```

### 对 Text 类型排序

```json
GET kibana_sample_data_ecommerce/_mapping

// 对 text 字段进行排序。默认会报错，需打开fielddata
POST /kibana_sample_data_ecommerce/_search
{
  "size": 5,
  "query": {
    "match_all": {

    }
  },
  "sort": [
    {"customer_full_name": {"order": "desc"}}
  ]
}

// 打开 text的 fielddata
PUT kibana_sample_data_ecommerce/_mapping
{
  "properties": {
    "customer_full_name" : {
          "type" : "text",
          "fielddata": true,
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        }
  }
}
```

### 排序的过程

- 排序是针对字段原始内容进行的。倒排索引无法发挥作用
- 需要用到正排索引。通过文档 ID 和字段快速得到字段原始内容
- ES 有 2 种实现方式
  - Fielddata
  - Doc Values (列式存储，对 Text 类型无效）

### Doc Values vs. Field Data

|          | Doc Values                     | Field data                                    |
| :------- | :----------------------------- | :-------------------------------------------- |
| 何时创建 | 索引时，和倒排索引一起创建     | 搜索时候动态创建                              |
| 创建位置 | 磁盘文件                       | JVM Heap                                      |
| 优点     | 避免大量内存占用               | 索引速度快，不占用额外的磁盘空间              |
| 缺点     | 降低索引速度，占用额外磁盘空间 | 文档过多时，动态创建开销大，占用过多 JVM Heap |
| 缺省值   | ES 2.x 之后                    | ES1.x 及之前                                  |

### 打开 Fielddata

- 默认关闭，可以通过 Mapping 设置打开。修改设置后，即时生效，无需缩减索引
- 其他字段类型不支持，支持对 Text 进行设定
- 打开后，可以对 Text 字段进行排序，但是是对分词后的 term 排序，所以，结果往往无法满足预期，不建议使用
- 部分情况下打开，满足一些聚合分析的特定需求

### 关闭 Doc Values

- 默认启动，可以通过 Mapping 设置关闭
  - 增加索引的速度 / 减少磁盘空间
- 如果重新打开，需要重建索引
- 什么时候需要关闭
  - 明确不需要做排序及聚合分析

```json
// 关闭 keyword的 doc values
PUT test_keyword
PUT test_keyword/_mapping
{
  "properties": {
    "user_name":{
      "type": "keyword",
      "doc_values":false
    }
  }
```

### 获取 Doc Values & Fielddata 中储存的内容

- Text 类型的不支持 Doc Values
- Text 类型打开 Fielddata 后，可以查看分词后的数据

```json
DELETE temp_users
PUT temp_users
PUT temp_users/_mapping
{
  "properties": {
    "name":{"type": "text","fielddata": true},
    "desc":{"type": "text","fielddata": true}
  }
}

POST temp_users/_doc
{"name":"Jack","desc":"Jack is a good boy!","age":10}

// 打开fielddata 后，查看 docvalue_fields数据
POST  temp_users/_search
{
  "docvalue_fields": [
    "name","desc"
    ]
}

// 查看整型字段的docvalues
POST  temp_users/_search
{
  "docvalue_fields": [
    "age"
    ]
}
```

**Fielddata Demo**

- 对Text字段设置fielddata ，支持随时修改
- Doc Values 可以在Mapping 中关闭，但是需要重新索引
- Text 不支持Doc Values
- 使用docvalue_fields 查看存储的信息

## 分页与遍历 - From, Size, Search After & Scorll API

### From / Size

- 默认情况下，查询按照相关度算分排序，返回前 10 条记录
- 容易理解的分页方案
  - From: 开始位置
  - Size: 期望获取文档的总数

```json
POST kibana_sample_data_ecommerce/_search
{
  "from": 10,
  "size": 20,
  "query": {
    "match_all": {

    }
  }
}
```

### 分布式系统中深度分页的问题

- ES 天生就是分布式，查询信息，但是数据分别保存在多个分片，多台机器，ES 天生就需要满足排序的需要（按照相关性算分）
- 当一个查询：From = 990 ，Size =10
  - 会在每个分片上先获取 1000 个文档。然后，通过 Coordinating Node 聚合所有结果。最后在通过排序选取前 1000 个文档
  - 页数越深，占用内容越多。为了避免深度分页带来的内存开销。ES 有个设定，默认限定到 10000 个文档
    - index.max_result_window

![14][14]

### Search After 避免深度分页的问题

- 避免深度分页的性能问题，可以实时获取下一页文档信息
  - 不支持指定页数（From）
  - 不能往下翻
- 第一步搜索需要指定 sort，并且保证值是唯一的（可以通过加入_id 保证唯一性）
- 然后使用上一次，最后一个文档的 sort 值进行查询

```json
DELETE users

POST users/_doc
{"name":"user1","age":10}

POST users/_doc
{"name":"user2","age":11}


POST users/_doc
{"name":"user2","age":12}

POST users/_doc
{"name":"user2","age":13}

POST users/_count

POST users/_search
{
    "size": 1,
    "query": {
        "match_all": {}
    },
    "sort": [
        {"age": "desc"} ,
        {"_id": "asc"}    
    ]
}

POST users/_search
{
    "size": 1,
    "query": {
        "match_all": {}
    },
    "search_after":
        [
          10,
          "ZQ0vYGsBrR8X3IP75QqX"],
    "sort": [
        {"age": "desc"} ,
        {"_id": "asc"}    
    ]
}
```

### Search After 是如何解决深度分页的问题

- 假设 Size 是 10
- 当查询 990 - 1000
- 通过唯一排序值定位，将每次要处理的文档都控制在 10

![15][15]

### Scoll API

- 创建一个快照，有新的数据写入以后，无法被查找
- 每次查询后，输入上一次的 Sroll ID

```json
DELETE users
POST users/_doc
{"name":"user1","age":10}

POST users/_doc
{"name":"user2","age":20}

POST users/_doc
{"name":"user3","age":30}

POST users/_doc
{"name":"user4","age":40}

POST /users/_search?scroll=5m
{
    "size": 1,
    "query": {
        "match_all" : {
        }
    }
}

POST users/_doc
{"name":"user5","age":50}
POST /_search/scroll
{
    "scroll" : "1m",
    "scroll_id" : "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAWAWbWdoQXR2d3ZUd2kzSThwVTh4bVE0QQ=="
}
```

### 不同的搜索类型和使用场景

- Regular
  - 需要实时获取顶部的部分文档。例如查询最新的订单
- Scorll
  - 需要全部文档，例如导出全部数据
- Pagination
  - From 和 Size
- 如何需要深度分页，则选用 Search After

## 处理并发读写操作

### 并发控制的必要性

- 两个 Web 程序同时更新某个文档，如果缺乏有效的并发，会导致更改的数据丢失
- 悲观并发控制
  - 假定有变更冲突的可能，会对资源加锁，防止冲突。例如数据库行锁
- 乐观并发控制
  - 假设突然是不会发生的，不会阻塞正在尝试的操作。如果数据在读写中被修改，更新将会失败。应用程序决定如何解决冲突，例如重试更新，使用新的数据，或者将错误报告给用户
- ES 采用的乐观并发控制

![16][16]

### ES 的乐观并发控制

- ES 中的文档是不可变更的。如果你更新一个文档，会将会文档标记为删除，同时增加一个全新当文档，同时文档的 version 字段加 1
- 内部版本控制
  - If_seq_no + If_primary_term
- 使用外部版本（使用其他数据库作为主要数据存储）
  - version + version_type = external

![17][17]

```json
DELETE products
PUT products
PUT products/_doc/1
{
  "title":"iphone",
  "count":100
}
GET products/_doc/1
//只能执行一次
PUT products/_doc/1?if_seq_no=0&if_primary_term=1
{
  "title":"iphone",
  "count":110
}
//数据库版本号为主
PUT products/_doc/1?version=23&version_type=external
{
  "title":"iphone",
  "count":130
}
```

## Bucket & Metric 聚合分析及嵌套聚合

### Bucket & Metric Aggregation

- Metric 一些系列的统计方法
- Bucket 一组满足条件的文档

![18][18]

### Aggregation 的语法

Aggregation 属于 Search 的一部分。一般情况下，建议将其 Size 指定为 0

![19][19]

**例子: 工资统计信息**

![20][20]

### Mertric Aggregation

- 单值分析：只输出一个分析结果
  - min，max，avg，sum
  - Cardinality（类似 distinct Count）
- 多值分析：输出多个分析结果
  - stats, extended stats
  - percentile, percentile rank
  - top hits （排在前面的示例）

### Metric 聚合的具体 Demo

- 查看最低工资
- 查看最高工资
- 一个聚合输出多个值
- 一次查询包含多个聚合
  - 同时查看最低, 最高和平均工资

```json
DELETE /employees
PUT /employees/
{
  "mappings" : {
      "properties" : {
        "age" : {
          "type" : "integer"
        },
        "gender" : {
          "type" : "keyword"
        },
        "job" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 50
            }
          }
        },
        "name" : {
          "type" : "keyword"
        },
        "salary" : {
          "type" : "integer"
        }
      }
    }
}

PUT /employees/_bulk
{ "index" : {  "_id" : "1" } }
{ "name" : "Emma","age":32,"job":"Product Manager","gender":"female","salary":35000 }
{ "index" : {  "_id" : "2" } }
{ "name" : "Underwood","age":41,"job":"Dev Manager","gender":"male","salary": 50000}
{ "index" : {  "_id" : "3" } }
{ "name" : "Tran","age":25,"job":"Web Designer","gender":"male","salary":18000 }
{ "index" : {  "_id" : "4" } }
{ "name" : "Rivera","age":26,"job":"Web Designer","gender":"female","salary": 22000}
{ "index" : {  "_id" : "5" } }
{ "name" : "Rose","age":25,"job":"QA","gender":"female","salary":18000 }
{ "index" : {  "_id" : "6" } }
{ "name" : "Lucy","age":31,"job":"QA","gender":"female","salary": 25000}
{ "index" : {  "_id" : "7" } }
{ "name" : "Byrd","age":27,"job":"QA","gender":"male","salary":20000 }
{ "index" : {  "_id" : "8" } }
{ "name" : "Foster","age":27,"job":"Java Programmer","gender":"male","salary": 20000}
{ "index" : {  "_id" : "9" } }
{ "name" : "Gregory","age":32,"job":"Java Programmer","gender":"male","salary":22000 }
{ "index" : {  "_id" : "10" } }
{ "name" : "Bryant","age":20,"job":"Java Programmer","gender":"male","salary": 9000}
{ "index" : {  "_id" : "11" } }
{ "name" : "Jenny","age":36,"job":"Java Programmer","gender":"female","salary":38000 }
{ "index" : {  "_id" : "12" } }
{ "name" : "Mcdonald","age":31,"job":"Java Programmer","gender":"male","salary": 32000}
{ "index" : {  "_id" : "13" } }
{ "name" : "Jonthna","age":30,"job":"Java Programmer","gender":"female","salary":30000 }
{ "index" : {  "_id" : "14" } }
{ "name" : "Marshall","age":32,"job":"Javascript Programmer","gender":"male","salary": 25000}
{ "index" : {  "_id" : "15" } }
{ "name" : "King","age":33,"job":"Java Programmer","gender":"male","salary":28000 }
{ "index" : {  "_id" : "16" } }
{ "name" : "Mccarthy","age":21,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "17" } }
{ "name" : "Goodwin","age":25,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "18" } }
{ "name" : "Catherine","age":29,"job":"Javascript Programmer","gender":"female","salary": 20000}
{ "index" : {  "_id" : "19" } }
{ "name" : "Boone","age":30,"job":"DBA","gender":"male","salary": 30000}
{ "index" : {  "_id" : "20" } }
{ "name" : "Kathy","age":29,"job":"DBA","gender":"female","salary": 20000}

// Metric 聚合，找到最低的工资
POST employees/_search
{
  "size": 0,
  "aggs": {
    "min_salary": {
      "min": {
        "field":"salary"
      }
    }
  }
}

// Metric 聚合，找到最高的工资
POST employees/_search
{
  "size": 0,
  "aggs": {
    "max_salary": {
      "max": {
        "field":"salary"
      }
    }
  }
}

// 多个 Metric 聚合，找到最低最高和平均工资
POST employees/_search
{
  "size": 0,
  "aggs": {
    "max_salary": {
      "max": {
        "field": "salary"
      }
    },
    "min_salary": {
      "min": {
        "field": "salary"
      }
    },
    "avg_salary": {
      "avg": {
        "field": "salary"
      }
    }
  }
}

// 一个聚合，输出多值
POST employees/_search
{
  "size": 0,
  "aggs": {
    "stats_salary": {
      "stats": {
        "field":"salary"
      }
    }
  }
}
```

### Bucket

- 按照一定的规则，将文档分配到不同的桶中，从而达到分类的目的。ES 提供的一些常见的 Bucket Aggregation
  - Terms
  - 数字类型
  - Range / Date Range
  - Histogram / Data Histogram
- 支持嵌套：也就在桶里在做分桶

![21][21]

### Terms Aggregation

- 字段需要打开 fielddata，才能进行 Terms Aggregation
  - Keyword 默认支持 doc_values
  - Text 需要在 Mapping 中 enable ，会按照分词后的结果进行分
- Demo
  - 对 job 和 job.keyword 进行聚合
  - 对性别进行 Terms 聚合
  - 指定 bucket size

```json
// 对keword 进行聚合
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job.keyword"
      }
    }
  }
}

// 对 Text 字段进行 terms 聚合查询，失败
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job"
      }
    }
  }
}

// 对 Text 字段打开 fielddata，支持terms aggregation
PUT employees/_mapping
{
  "properties" : {
    "job":{
       "type":     "text",
       "fielddata": true
    }
  }
}

// 对job.keyword 和 job 进行 terms 聚合，分桶的总数并不一样
POST employees/_search
{
  "size": 0,
  "aggs": {
    "cardinate": {
      "cardinality": {
        "field": "job"
      }
    }
  }
}

// 对 性别的 keyword 进行聚合
POST employees/_search
{
  "size": 0,
  "aggs": {
    "gender": {
      "terms": {
        "field":"gender"
      }
    }
  }
}
```

### Cardinality

类似 SQL 中的 Distinct

```json
POST employees/_search
{
  "size": 0,
  "aggs": {
    "cardinate": {
      "cardinality": {
        "field":"job.keyword"
      }
    }
  }
}
```

### Bucket Size & Top Hists Demo

- 应用场景：当后去分桶后，桶内最匹配的顶部文档列表
- Size : 按年龄分桶，找出指定数据量的分桶信息
- Top Hits：查看各个工种中，年纪最大的 3 名员工

```json
// 指定 bucket 的 size
POST employees/_search
{
  "size": 0,
  "aggs": {
    "ages_5": {
      "terms": {
        "field":"age",
        "size":3
      }
    }
  }
}

// 指定size，不同工种中，年纪最大的3个员工的具体信息
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job.keyword"
      },
      "aggs":{
        "old_employee":{
          "top_hits":{
            "size":3,
            "sort":[
              {
                "age":{
                  "order":"desc"
                }
              }
            ]
          }
        }
      }
    }
  }
}
```

### 优化 Terms 聚合的性能

在聚合经常发生，性能高的，索引不断写入

![22][22]

> https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html

### Range & Histogram 聚合

- 按照数字的范围，进行分桶
- 在 Range Aggregation 中，可以自定义 Key
- Demo：
  - 按照工资的 Range 分桶
  - 按照工资的间隔（Histogram）分桶

```json
// Salary Ranges 分桶，可以自己定义 key
POST employees/_search
{
  "size": 0,
  "aggs": {
    "salary_range": {
      "range": {
        "field":"salary",
        "ranges":[
          {
            "to":10000
          },
          {
            "from":10000,
            "to":20000
          },
          {
            "key":">20000",
            "from":20000
          }
        ]
      }
    }
  }
}

// Salary Histogram,工资0到10万，以 5000一个区间进行分桶
POST employees/_search
{
  "size": 0,
  "aggs": {
    "salary_histrogram": {
      "histogram": {
        "field":"salary",
        "interval":5000,
        "extended_bounds":{
          "min":0,
          "max":100000

        }
      }
    }
  }
}
```

### Bucket + Metric Aggregation

- Bucket 聚合分析允许通过添加子聚合分析进一步分析，子聚合分析可以是
  - Bucket
  - Metric
- Demo
  - 按照工作类型进行分桶，并统计工资信息
  - 先按照工作类型分桶，然后按性别分桶，并统计工资信息

```json
// 嵌套聚合1，按照工作类型分桶，并统计工资信息
POST employees/_search
{
  "size": 0,
  "aggs": {
    "Job_salary_stats": {
      "terms": {
        "field": "job.keyword"
      },
      "aggs": {
        "salary": {
          "stats": {
            "field": "salary"
          }
        }
      }
    }
  }
}

// 多次嵌套。根据工作类型分桶，然后按照性别分桶，计算工资的统计信息
POST employees/_search
{
  "size": 0,
  "aggs": {
    "Job_gender_stats": {
      "terms": {
        "field": "job.keyword"
      },
      "aggs": {
        "gender_stats": {
          "terms": {
            "field": "gender"
          },
          "aggs": {
            "salary_stats": {
              "stats": {
                "field": "salary"
              }
            }
          }
        }
      }
    }
  }
}
```

## Pipeline 聚合分析

### 一个例子：Pipeline：min_bucket

- 在员工数最多的工种里，找出平均工资最低的工种
  
![23][23]

### Pipeline

- 管道的概念：支持对聚合分析的结果，再次进行聚合分析
- Pipeline 的分析结果会输出到原结果汇总，根据位置的不同，分为两类
  - Sibling - 结果和现有分析结果同级
    - Max, min, Avg & Sum Bucket
    - Stats, Extened Status Bucket
    - Percentiles Bucket
  - Parent - 结果内嵌到现有的聚合分析结果之中
    - Derivative（求导）
    - Cumultive Sum（累计求和）
    - Moving Function（滑动窗口）
  
### Sibling Pipeline 的例子

- 对不同类型工作的，平均工资
  - 求最大
  - 平均
  - 统计信息
  - 百分位数

```json
DELETE employees
PUT /employees/_bulk
{ "index" : {  "_id" : "1" } }
{ "name" : "Emma","age":32,"job":"Product Manager","gender":"female","salary":35000 }
{ "index" : {  "_id" : "2" } }
{ "name" : "Underwood","age":41,"job":"Dev Manager","gender":"male","salary": 50000}
{ "index" : {  "_id" : "3" } }
{ "name" : "Tran","age":25,"job":"Web Designer","gender":"male","salary":18000 }
{ "index" : {  "_id" : "4" } }
{ "name" : "Rivera","age":26,"job":"Web Designer","gender":"female","salary": 22000}
{ "index" : {  "_id" : "5" } }
{ "name" : "Rose","age":25,"job":"QA","gender":"female","salary":18000 }
{ "index" : {  "_id" : "6" } }
{ "name" : "Lucy","age":31,"job":"QA","gender":"female","salary": 25000}
{ "index" : {  "_id" : "7" } }
{ "name" : "Byrd","age":27,"job":"QA","gender":"male","salary":20000 }
{ "index" : {  "_id" : "8" } }
{ "name" : "Foster","age":27,"job":"Java Programmer","gender":"male","salary": 20000}
{ "index" : {  "_id" : "9" } }
{ "name" : "Gregory","age":32,"job":"Java Programmer","gender":"male","salary":22000 }
{ "index" : {  "_id" : "10" } }
{ "name" : "Bryant","age":20,"job":"Java Programmer","gender":"male","salary": 9000}
{ "index" : {  "_id" : "11" } }
{ "name" : "Jenny","age":36,"job":"Java Programmer","gender":"female","salary":38000 }
{ "index" : {  "_id" : "12" } }
{ "name" : "Mcdonald","age":31,"job":"Java Programmer","gender":"male","salary": 32000}
{ "index" : {  "_id" : "13" } }
{ "name" : "Jonthna","age":30,"job":"Java Programmer","gender":"female","salary":30000 }
{ "index" : {  "_id" : "14" } }
{ "name" : "Marshall","age":32,"job":"Javascript Programmer","gender":"male","salary": 25000}
{ "index" : {  "_id" : "15" } }
{ "name" : "King","age":33,"job":"Java Programmer","gender":"male","salary":28000 }
{ "index" : {  "_id" : "16" } }
{ "name" : "Mccarthy","age":21,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "17" } }
{ "name" : "Goodwin","age":25,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "18" } }
{ "name" : "Catherine","age":29,"job":"Javascript Programmer","gender":"female","salary": 20000}
{ "index" : {  "_id" : "19" } }
{ "name" : "Boone","age":30,"job":"DBA","gender":"male","salary": 30000}
{ "index" : {  "_id" : "20" } }
{ "name" : "Kathy","age":29,"job":"DBA","gender":"female","salary": 20000}
```

```json
// 平均工资最低的工作类型
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "min_salary_by_job":{
      "min_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}

// 平均工资最高的工作类型
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "max_salary_by_job":{
      "max_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}

// 平均工资的平均工资
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "avg_salary_by_job":{
      "avg_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}

// 平均工资的统计分析
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "stats_salary_by_job":{
      "stats_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}

// 平均工资的百分位数
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "percentiles_salary_by_job":{
      "percentiles_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}
```

### Parent Pipeline: Derivative

按年龄、对工资进行求导（看工资发展的趋势）

![24][24]

```json
// 按照年龄对平均工资求导 
POST employees/_search
{
"size": 0,
"aggs": {
  "age": {
    "histogram": {
      "field": "age",
      "min_doc_count": 1,
      "interval": 1
    },
    "aggs": {
      "avg_salary": {
        "avg": {
          "field": "salary"
        }
      },
      "derivative_avg_salary":{
        "derivative": {
          "buckets_path": "avg_salary"
        }
      }
    }
  }
}
}
//return 
"aggregations" : {
  "age" : {
    "buckets" : [
      {
        "key" : 20.0,
        "doc_count" : 1,
        "avg_salary" : {
          "value" : 9000.0
        }
      },
      {
        "key" : 21.0,
        "doc_count" : 1,
        "avg_salary" : {
          "value" : 16000.0
        },
        "derivative_avg_salary" : {
          "value" : 7000.0
        }
      }
  ]
}
```

### Parent Pipeline

- 年龄直方图划分的平均工资
  - Cumulative Sum
  - Moving Function

```json
// Cumulative_sum
POST employees/_search
{
  "size": 0,
  "aggs": {
    "age": {
      "histogram": {
        "field": "age",
        "min_doc_count": 1,
        "interval": 1
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        },
        "cumulative_salary":{
          "cumulative_sum": {
            "buckets_path": "avg_salary"
          }
        }
      }
    }
  }
}

// Moving Function
POST employees/_search
{
  "size": 0,
  "aggs": {
    "age": {
      "histogram": {
        "field": "age",
        "min_doc_count": 1,
        "interval": 1
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        },
        "moving_avg_salary":{
          "moving_fn": {
            "buckets_path": "avg_salary",
            "window":10,
            "script": "MovingFunctions.min(values)"
          }
        }
      }
    }
  }
}
```

## 聚合的作用范围及排序

### 聚合的作用范围

- ES 聚合分析的默认作用范围是 query 的查询结果集
- 同时 ES 还支持以下方式改变聚合的作用范围
  - Filter
  - Post_Filter
  - Global

```json
// Query
POST employees/_search
{
  "size": 0,
  "query": {
    "range": {
      "age": {
        "gte": 20
      }
    }
  },
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job.keyword"
        
      }
    }
  }
}
```

### Filter

![25][25]

```json
// Filter
POST employees/_search
{
  "size": 0,
  "aggs": {
    "older_person": {
      "filter":{
        "range":{
          "age":{
            "from":35
          }
        }
      },
      "aggs":{
         "jobs":{
           "terms": {
        "field":"job.keyword"
      }
      }
    }},
    "all_jobs": {
      "terms": {
        "field":"job.keyword"
        
      }
    }
  }
}
```

### Post_Filter

- 是对聚合分析后的文档进行再次过滤
- Size 无需设置为 0
- 使用场景
  - 一条语句，获取聚合信息 + 获取符合条件的文档

```json
// Post field. 一条语句，找出所有的job类型。还能找到聚合后符合条件的结果
POST employees/_search
{
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword"
      }
    }
  },
  "post_filter": {
    "match": {
      "job.keyword": "Dev Manager"
    }
  }
}
```

### Global

```json
// global
POST employees/_search
{
  "size": 0,
  "query": {
    "range": {
      "age": {
        "gte": 40
      }
    }
  },
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job.keyword"
      }
    },
    "all":{
      "global": {}, // Golbal，无视query，对全部文档进行统计
      "aggs":{
        "salary_avg":{
          "avg":{
            "field":"salary"
          }
        }
      }
    }
  }
}
```

### 排序

- 指定 order，按照 count 和 key 排序
  - 默认情况，按照 count 降序排序
  - 指定 size，就能返回相应的桶

```json
// 排序 order
// count正序 and key倒叙
POST employees/_search
{
"size": 0,
"query": {
  "range": {
    "age": {
      "gte": 20
    }
  }
},
"aggs": {
  "jobs": {
    "terms": {
      "field": "job.keyword",
      "order": [
        {
          "_count": "asc"
        },
        {
          "_key": "desc"
        }
      ]
    }
  }
}
}
```

### 基于子聚合的值排序

- 基于子聚合的数值进行排序

```json
POST employees/_search
{
"size": 0,
"aggs": {
  "jobs": {
    "terms": {
      "field": "job.keyword",
      "order": [
        {
          "avg_salary": "desc"
        }
      ]
    },
    "aggs": {
      "avg_salary": {
        "avg": {
          "field": "salary"
        }
      }
    }
  }
}
}
```

- 使用子聚合，Aggregation name

```json
POST employees/_search
{
"size": 0,
"aggs": {
  "jobs": {
    "terms": {
      "field": "job.keyword",
      "order": [
        {
          "stats_salary.min": "desc"
        }
      ]
    },
    "aggs": {
      "stats_salary": {
        "stats": {
          "field": "salary"
        }
      }
    }
  }
}
}
```

## 聚合分析的原理及精准度问题

### 分布式系统的近似统计算法

![26][26]

### Min 聚合分析的执行流程

![28][28]

### Terms Aggregation 的返回值

- 在 Terms Aggregation 的返回中有两个特殊的数值
  - doc_count_error_upper_bound：被遗漏的 term 分桶，包含的文档，有可能的最大值
  - sum_other_doc_count: 除了返回结果 bucket 的 terms 以外，其他 terms 的文档总数（总数 - 返回的总数）

![29][29]

### Terms 聚合分析的执行流程

![30][30]

### Terms 不正确的案例

![31][31]

### 如何解决 Terms 不准的问题：提升 shard_size 的参数

- Terms 聚合分析不准的原因，数据分散在多个分片上，Coordinating Node 无法获取数据全貌
- 解决方案 1：当数据量不大时，设置 Primary Shard 为 1；实现准确性
- 解决方案 2：在分布式数据上，设置 shard_size 参数，提高精确度
  - 原理：每次从 Shard 上额外多获取数据，提升准确率

![32][32]

### 打开 show_term_doc_count_error

![33][33]

### shard_size 设定

- 调整 shard size 大小，降低 doc_count_error_upper_bound 来提升准确度
  - 增加整体计算量，提高了准确率，但会降低相应时间
- Shard Size 默认大小设定
  - shard size = size * 1.5 +10
  - https://www.elastic.co/guide/en/elasticsearch/reference/7.2/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-approximate-counts

```json
DELETE my_flights
PUT my_flights
{
  "settings": {
    "number_of_shards": 20
  },
  "mappings" : {
      "properties" : {
        "AvgTicketPrice" : {
          "type" : "float"
        },
        "Cancelled" : {
          "type" : "boolean"
        },
        "Carrier" : {
          "type" : "keyword"
        },
        "Dest" : {
          "type" : "keyword"
        },
        "DestAirportID" : {
          "type" : "keyword"
        },
        "DestCityName" : {
          "type" : "keyword"
        },
        "DestCountry" : {
          "type" : "keyword"
        },
        "DestLocation" : {
          "type" : "geo_point"
        },
        "DestRegion" : {
          "type" : "keyword"
        },
        "DestWeather" : {
          "type" : "keyword"
        },
        "DistanceKilometers" : {
          "type" : "float"
        },
        "DistanceMiles" : {
          "type" : "float"
        },
        "FlightDelay" : {
          "type" : "boolean"
        },
        "FlightDelayMin" : {
          "type" : "integer"
        },
        "FlightDelayType" : {
          "type" : "keyword"
        },
        "FlightNum" : {
          "type" : "keyword"
        },
        "FlightTimeHour" : {
          "type" : "keyword"
        },
        "FlightTimeMin" : {
          "type" : "float"
        },
        "Origin" : {
          "type" : "keyword"
        },
        "OriginAirportID" : {
          "type" : "keyword"
        },
        "OriginCityName" : {
          "type" : "keyword"
        },
        "OriginCountry" : {
          "type" : "keyword"
        },
        "OriginLocation" : {
          "type" : "geo_point"
        },
        "OriginRegion" : {
          "type" : "keyword"
        },
        "OriginWeather" : {
          "type" : "keyword"
        },
        "dayOfWeek" : {
          "type" : "integer"
        },
        "timestamp" : {
          "type" : "date"
        }
      }
    }
}

POST _reindex
{
  "source": {
    "index": "kibana_sample_data_flights"
  },
  "dest": {
    "index": "my_flights"
  }
}

GET kibana_sample_data_flights/_count
GET my_flights/_count

get kibana_sample_data_flights/_search

GET kibana_sample_data_flights/_search
{
  "size": 0,
  "aggs": {
    "weather": {
      "terms": {
        "field":"OriginWeather",
        "size":5,
        "show_term_doc_count_error":true
      }
    }
  }
}

GET my_flights/_search
{
  "size": 0,
  "aggs": {
    "weather": {
      "terms": {
        "field":"OriginWeather",
        "size":1,
        "shard_size":1,
        "show_term_doc_count_error":true
      }
    }
  }
}
```

## 对象及 Nested 对象

### 数据的关联关系

- 真实世界中有很多重要的关联关系
  - 博客、作者、评论
  - 银行账户有多次交易记录
  - 客户有很多银行账户
  - 目录文件有很多文件和子目录

### 关系型数据库的范式化设计

- 范式化设计（Normalization）的主要目标是 “减少不必要的更新”
- 副作用：一个完全范式化设计的数据库经常面临 “查询缓慢” 的问题
  - 数据库越范式化，就需要 Join 越多的表
- 范式化节省了储存空间，但是储存空间越来越便宜
- 范式化简化了更新，但是数据 “读” 取操作可能越多

![34][34]

### Denormalization

- 反范式化设计
  - 数据 “Flattening”, 不使用关联关系，而是在文档中保存冗余的数据拷贝
- 优点：无需处理 Joins 操作，数据读取性能好
  - Elasticsearch 通过压缩_source 字段，减少磁盘空间的开销
- 缺点：不适合在数据频繁修改的场景
  - 一条数据（用户名）的改动，可能会引起很多数据的更新

### 在 Elasticsearch 中处理关联关系

- 关系型数据库，一般会考虑 Normalize 数据；在 Elasticsearch，往往考虑 Denormalize 数据
  - Denormalize 的好处：读的速度变快、无需表连接、无需行锁
- Elasticsearch 并不擅长处理关联关系，我们一般采用以下四种方法处理关联
  - 对象类型
  - 嵌套对象（Nested Object）
  - 父子关联关系（Parent / Child）
  - 应用端关联

### 案例 1：博客和其作者信息

- 对象类型
  - 在每个博客的问下中都保留作者的信息
  - 如果作者信息发生变化，需要修改相关的博客文档

```json
DELETE blog
// 设置blog的 Mapping
PUT /blog
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text"
      },
      "time": {
        "type": "date"
      },
      "user": {
        "properties": {
          "city": {
            "type": "text"
          },
          "userid": {
            "type": "long"
          },
          "username": {
            "type": "keyword"
          }
        }
      }
    }
  }
}

// 插入一条 Blog 信息
PUT blog/_doc/1
{
  "content":"I like Elasticsearch",
  "time":"2019-01-01T00:00:00",
  "user":{
    "userid":1,
    "username":"Jack",
    "city":"Shanghai"
  }
}

// 通过一条查询语句即可获取到博客和作者信息
// 查询 Blog 信息
POST blog/_search
{
  "query": {
    "bool": {
      "must": [
        {"match": {"content": "Elasticsearch"}},
        {"match": {"user.username": "Jack"}}
      ]
    }
  }
}
```

### 案例 2：包含对象数组的文档

```json
DELETE my_movies
// 电影的Mapping信息
PUT my_movies
{
      "mappings" : {
      "properties" : {
        "actors" : {
          "properties" : {
            "first_name" : {
              "type" : "keyword"
            },
            "last_name" : {
              "type" : "keyword"
            }
          }
        },
        "title" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        }
      }
    }
}

// 写入一条电影信息
POST my_movies/_doc/1
{
  "title":"Speed",
  "actors":[
    {
      "first_name":"Keanu",
      "last_name":"Reeves"
    },

    {
      "first_name":"Dennis",
      "last_name":"Hopper"
    }

  ]
}

// 查询电影信息
POST my_movies/_search
{
  "query": {
    "bool": {
      "must": [
        {"match": {"actors.first_name": "Keanu"}},
        {"match": {"actors.last_name": "Hopper"}}
      ]
    }
  }
}
```

### 为啥会搜到不需要的结果？

- 储存时，内部对象的边界没有在考虑在内，JSON 格式被处理成扁平键值对的结构
- 当对多个字段进行查询时，导致了意外的搜索结果
- 可以用 Nested Data Type 解决这个问题

### Nested Data Type

- Nested 数据类型：允许对象数组中的对象被独立索引
- 使用 nested 和 properties 关键词，将所有 actors 索引到多个分隔的文档
- 在内部，Nested 文档会被保存在两个 Lucene 文档中，查询时做 Join 处理

```json
PUT my_movies
{
  "mappings" : {
    "properties" : {
      "actors" : {
        "type": "nested",
        "properties" : {
          "first_name" : {"type" : "keyword"},
          "last_name" : {"type" : "keyword"}
        }},
      "title" : {
        "type" : "text",
        "fields" : {"keyword":{"type":"keyword","ignore_above":256}}
      }
    }
  }
}
```

### 嵌套查询

在内部，Nested 文档被保存在两个 Lucene 文档中，会在查询时做 Join 处理

![35][35]

```json
// Nested 查询
POST my_movies/_search
{
  "query": {
    "bool": {
      "must": [
        {"match": {"title": "Speed"}},
        {
          "nested": {
            "path": "actors",
            "query": {
              "bool": {
                "must": [
                  {"match": {
                    "actors.first_name": "Keanu"
                  }},
                  {"match": {
                    "actors.last_name": "Hopper"
                  }}
                ]
              }
            }
          }
        }
      ]
    }
  }
}
//返回
 "hits" : {
    "total" : {
      "value" : 0,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [ ]
  }
```

### 嵌套聚合

```json
# Nested Aggregation
POST my_movies/_search
{
  "size": 0,
  "aggs": {
    "actors": {
      "nested": {
        "path": "actors"
      },
      "aggs": {
        "actor_name": {
          "terms": {
            "field": "actors.first_name",
            "size": 10
          }
        }
      }
    }
  }
}

// 普通 aggregation不工作
POST my_movies/_search
{
  "size": 0,
  "aggs": {
    "NAME": {
      "terms": {
        "field": "actors.first_name",
        "size": 10
      }
    }
  }
}
```

## 文档的父子关系

### Parent / Child

- 对象和 Nested 对象的局限性
  - 每次更新，需要重新索引整个对象（包括跟对象和嵌套对象）
- ES 提供了类似关系型数据库中 Join 的实现。使用 Join 数据类型实现，可以通过维护 Parent / Child 的关系，从而分离两个对象
  - 父文档和子文档是两个独立的文档
  - 更新父文档无需重新索引整个子文档。子文档被新增，更改和删除也不会影响到父文档和其他子文档。

### 父子关系

- 定义父子关系的几个步骤
  - 设置索引的 Mapping
  - 索引父文档
  - 索引子文档
  - 按需查询文档

### 设置 Mapping

![36][36]

```json
DELETE my_blogs
// 设定 Parent/Child Mapping
PUT my_blogs
{
  "settings": {
    "number_of_shards": 2
  },
  "mappings": {
    "properties": {
      "blog_comments_relation": {
        "type": "join",
        "relations": {
          "blog": "comment"
        }
      },
      "content": {
        "type": "text"
      },
      "title": {
        "type": "keyword"
      }
    }
  }
}
```

### 索引父文档

![37][37]

```json
PUT my_blogs/_doc/blog1
{
  "title":"Learning Elasticsearch",
  "content":"learning ELK @ geektime",
  "blog_comments_relation":{
    "name":"blog"
  }
}

PUT my_blogs/_doc/blog2
{
  "title":"Learning Hadoop",
  "content":"learning Hadoop",
    "blog_comments_relation":{
    "name":"blog"
  }
}
```

### 索引子文档

- 父文档和子文档必须存在相同的分片上
  - 确保查询 join 的性能
- 当指定子文档时候，必须指定它的父文档 ID
  - 使用 route 参数来保证，分配到相同的分片

![38][38]

```json
// 索引子文档
PUT my_blogs/_doc/comment1?routing=blog1
{
  "comment":"I am learning ELK",
  "username":"Jack",
  "blog_comments_relation":{
    "name":"comment",
    "parent":"blog1"
  }
}

PUT my_blogs/_doc/comment2?routing=blog2
{
  "comment":"I like Hadoop!!!!!",
  "username":"Jack",
  "blog_comments_relation":{
    "name":"comment",
    "parent":"blog2"
  }
}

PUT my_blogs/_doc/comment3?routing=blog2
{
  "comment":"Hello Hadoop",
  "username":"Bob",
  "blog_comments_relation":{
    "name":"comment",
    "parent":"blog2"
  }
}
```

### Parent / Child 所支持的查询

- 查询所有文档
- Parent Id 查询
- Has Child 查询
- Has Parent 查询

```json
// 查询所有文档
POST my_blogs/_search
{}

// 根据父文档ID查看
GET my_blogs/_doc/blog2

// Parent Id 查询
POST my_blogs/_search
{
"query": {
  "parent_id": {
    "type": "comment",
    "id": "blog2"
  }
}
}

// Has Child 查询,返回父文档
POST my_blogs/_search
{
"query": {
  "has_child": {
    "type": "comment",
    "query" : {
          "match": {
              "username" : "Jack"
          }
      }
  }
}
}

// Has Parent 查询，返回相关的子文档
POST my_blogs/_search
{
"query": {
  "has_parent": {
    "parent_type": "blog",
    "query" : {
          "match": {
              "title" : "Learning Hadoop"
          }
      }
  }
}
}
```

### 使用 has_child 查询

- 返回父文档
- 通过对子文档进行查询
  - 返回具体相关子文档的父文档
  - 父子文档在相同的分片上，因此 Join 效率高

![39][39]

### 使用 has_parent 查询

- 返回相关性的子文档
- 通过对父文档进行查询
  - 返回相关的子文档

![40][40]

### 使用 parent_id 查询

- 返回所有相关子文档
- 通过对付文档 Id 进行查询
  - 返回所有相关的子文档

![41][41]

### 访问子文档

需指定父文档 routing 参数

![42][42]

```json
// 通过ID ，访问子文档
GET my_blogs/_doc/comment2

// 通过ID和routing ，访问子文档
GET my_blogs/_doc/comment3?routing=blog2
```

### 更新子文档

更新子文档不会影响到父文档

```json
// 更新子文档
PUT my_blogs/_doc/comment3?routing=blog2
{
    "comment": "Hello Hadoop??",
    "blog_comments_relation": {
      "name": "comment",
      "parent": "blog2"
    }
}
```

### 嵌套对象 v.s 父子文档

|          | Nested Object                        | Parent / Child                           |
| :------- | :----------------------------------- | :--------------------------------------- |
| 优点     | 文档存储在一起，读取性能高           | 父子文档可以独立更新                     |
| 缺点     | 更新嵌套的子文档时，需要更新整个文档 | 需要额外的内存去维护关系。读取性能相对差 |
| 适用场景 | 子文档偶尔更新，以查询为主           | 子文档更新频繁                           |

## Update By Query & Reindex API

## 使用场景

- 一般在以下几种情况时，我们需要重建索引：
  - 索引的 Mappings 发生变更：字段类型更改，分词器及字典更新
  - 索引的 Setting 发生变更：索引的主分片数发生改变
  - 集群内，集群间需要做数据迁移
- ElastiicSearch 的内置提供的 API
  - Update By Query : 在现有索引上重建
  - Reindex：在其他索引上重建索引

### 案例一：为索引增加子字段

- 改变 Mapping ， 增加子字段，使用英文分词器
- 此时尝试对子字段进行查询
- 虽然有数据已经存在，但是没有返回结果

![43][43]

### Update By Query

- 执行 Update By Query
- 尝试对 Multi-Fields 查询查询
- 返回结果

![44][44]

```json
// 写入文档
PUT blogs/_doc/1
{
  "content":"Hadoop is cool",
  "keyword":"hadoop"
}

// 修改 Mapping，增加子字段，使用英文分词器
PUT blogs/_mapping
{
  "properties" : {
    "content" : {
      "type" : "text",
      "fields" : {
        "english" : {
          "type" : "text",
          "analyzer":"english"
        }
      }
    }
  }
}

// 写入文档
PUT blogs/_doc/2
{
  "content":"Elasticsearch rocks",
  "keyword":"elasticsearch"
}

// 查询新写入文档
POST blogs/_search
{
  "query": {
    "match": {
      "content.english": "Elasticsearch"
    }
  }
}

// 查询 Mapping 变更前写入的文档
POST blogs/_search
{
  "query": {
    "match": {
      "content.english": "hadoop"
    }
  }
}

// Update所有文档
POST blogs/_update_by_query
{
}
```

### 案例二：更改已有字段类型的 Mappings

- ES 不允许在原有 Mapping 上对字段类型进行修改
- 只能创建新的索引，并设定正确的字段类型，在重新导入数据

![45][45]

```json
// 创建新的索引并且设定新的Mapping
PUT blogs_fix/
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "fields": {
          "english": {
            "type": "text",
            "analyzer": "english"
          }
        }
      },
      "keyword": {
        "type": "keyword"
      }
    }
  }
}

// Reindx API
POST _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix"
  }
}

GET  blogs_fix/_doc/1

// 测试 Term Aggregation
POST blogs_fix/_search
{
  "size": 0,
  "aggs": {
    "blog_keyword": {
      "terms": {
        "field": "keyword",
        "size": 10
      }
    }
  }
}
```

### Reindex API

- Reindex API 支持把文档从一个索引拷贝到另外一个索引
- 使用 Reindex API 的一些场景
  - 修改索引的主分片数
  - 改变字段的 Mapping 中的字段类型
  - 集群中数据迁移、跨集群的数据迁移

```json
// Reindx API，version Type Internal
POST  _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix",
    "version_type": "internal"
  }
}

// 文档版本号增加
GET  blogs_fix/_doc/1

// Reindx API，version Type Internal
POST  _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix",
    "version_type": "external"
  }
}

// Reindx API，version Type Internal
POST  _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix",
    "version_type": "external"
  },
  "conflicts": "proceed"
}
```

### 两个注意点

- 索引的 mapping _source 要开启
- 先创建一个新索引，然后在执行 reindex

### OP Type

- _reindex 指挥创建不存在的文档
- 文档如果存在，会导致版本冲突

```json
// Reindx API，version Type Internal
POST _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix",
    "op_type": "create"
  }
}
```

### 跨集群 ReIndex

![46][46]

### 查看 Task API

![47][47]

### 回顾

- Update By Query 使用场景： 为字段新增子字段；字段更改分词器；更新分词器词库
- Reindex API 使用场景：修改字段类型
  - 需要先对新索引设置 Mapping，索引的设置和映射关系不会被复制
- 通过查看 Task API，了解 Reindex 的状况
- Remote ReIndex ，需要修改 elasticsearch.yml 配置并且重启
- 一定要尽量使用 Index Alias 读写数据。即便发生 Reindex，也能实现零停机维护

## Ingest Pipeline 与 Painless Script

### 需求：修复与增强写入的数据

- Tags 字段中，逗号分割的文本应该是数组，而不是一个字符串
- 需求：后期需要对 Tags 进行 Aggregation 统计信息

```json
// Blog数据，包含3个字段，tags用逗号间隔
PUT tech_blogs/_doc/1
{
  "title":"Introducing big data......",
  "tags":"hadoop,elasticsearch,spark",
  "content":"You konw, for big data"
}
```

### Ingest Node

- Elasticsearch 5.0 后，引入的一种新的节点类型。默认配置下，每个节点都是 Ingest Node
  - 具有预处理数据的能力，可拦截 Index 或者 Bulck API 的请求
  - 对数据进行转换，并重新返回给 Index 和 Bluck API
- 无需 Logstash ，就可以进行数据的预处理，例如
  - 为某个字段设置默认值；重命名某个字段的字段名；对字段值进行 Split 操作
  - 支持设置 Painless 脚本，对数据进行更加复杂的加工

### Pipeline & Processor

- Pipeline - 管道会对通过的数据（文档），按照顺序进行加工
- Processor - Elasticsearch 对一些加工的行为进行了抽象包装
  - Elasticsearch 有很多内置的 Processors。也支持通过插件的方式，实现自己的 Processsor

![48][48]

### 使用 Pipeline 切分字符串

![49][49]

```json
// 测试split tags
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "description": "to split blog tags",
    "processors": [
      {
        "split": {
          "field": "tags",
          "separator": ","
        }
      }
    ]
  },
  "docs": [
    {
      "_index": "index",
      "_id": "id",
      "_source": {
        "title": "Introducing big data......",
        "tags": "hadoop,elasticsearch,spark",
        "content": "You konw, for big data"
      }
    },
    {
      "_index": "index",
      "_id": "idxx",
      "_source": {
        "title": "Introducing cloud computering",
        "tags": "openstack,k8s",
        "content": "You konw, for cloud"
      }
    }
  ]
}
```

### 为文档增加字段

![50][50]

```json
// 同时为文档，增加一个字段。blog查看量
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "description": "to split blog tags",
    "processors": [
      {
        "split": {
          "field": "tags",
          "separator": ","
        }
      },
      {
        "set": {
          "field": "views",
          "value": 0
        }
      }
    ]
  },
  "docs": [
    {
      "_index": "index",
      "_id": "id",
      "_source": {
        "title": "Introducing big data......",
        "tags": "hadoop,elasticsearch,spark",
        "content": "You konw, for big data"
      }
    },
    {
      "_index": "index",
      "_id": "idxx",
      "_source": {
        "title": "Introducing cloud computering",
        "tags": "openstack,k8s",
        "content": "You konw, for cloud"
      }
    }
  ]
}
```

### Pipeline API

![51][51]

### 添加 Pipeline 并测试

```json
// 为ES添加一个 Pipeline
PUT _ingest/pipeline/blog_pipeline
{
  "description": "a blog pipeline",
  "processors": [
    {
      "split": {
        "field": "tags",
        "separator": ","
      }
    },
    {
      "set": {
        "field": "views",
        "value": 0
      }
    }
  ]
}

//查看Pipleline
GET _ingest/pipeline/blog_pipeline

//测试pipeline
POST _ingest/pipeline/blog_pipeline/_simulate
{
  "docs": [
    {
      "_source": {
        "title": "Introducing cloud computering",
        "tags": "openstack,k8s",
        "content": "You konw, for cloud"
      }
    }
  ]
}
```

### Index & Update By Query

![52][52]

```json
//不使用pipeline更新数据
PUT tech_blogs/_doc/1
{
  "title":"Introducing big data......",
  "tags":"hadoop,elasticsearch,spark",
  "content":"You konw, for big data"
}

//使用pipeline更新数据
PUT tech_blogs/_doc/2?pipeline=blog_pipeline
{
  "title": "Introducing cloud computering",
  "tags": "openstack,k8s",
  "content": "You konw, for cloud"
}

//查看两条数据，一条被处理，一条未被处理
POST tech_blogs/_search
{}

//update_by_query 会导致错误
POST tech_blogs/_update_by_query?pipeline=blog_pipeline
{
}

//增加update_by_query的条件
POST tech_blogs/_update_by_query?pipeline=blog_pipeline
{
  "query": {
    "bool": {
      "must_not": {
        "exists": {
          "field": "views"
        }
      }
    }
  }
}
```

### 一些内置的 Processors

https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html

- Split Processor （例如：将给定字段分成一个数组）
- Remove / Rename Processor （移除一个重命名字段）
- Append（为商品增加一个新的标签）
- Convert （将商品价格，从字符串转换成 float 类型）
- Date / JSON （日期格式转换，字符串转 JSON 对象）
- Date Index Name Processor （将通过该处理器的文档，分配到指定时间格式的索引中）
- Fail Processor （一旦出现异常，该 Pipeline 指定的错误信息能返回给用户）
- Foreach Process （数组字段，数组的每个元素都会使用到一个相同的处理器）
- Grok Processor （日志的日志格式切割）
- Gsub / Join / Split （字符串替换、数组转字符串、字符串转数组）
- Lowercase / Upcase（大小写转换）

### Ingest Node v.s Logstash

|                | Logstash                                   | Ingest Node                                                 |
| :------------- | :----------------------------------------- | :---------------------------------------------------------- |
| 数据输入与输出 | 支持从不同的数据源读取，并写入不同的数据源 | 支持从 ES REST API 获取数据，并且写入 ES                    |
| 数据源缓冲     | 实现了简单的数据队列，支持重写             | 不支持缓冲                                                  |
| 数据处理       | 支持大量的的插件，也支持定制开发           | 内置的插件，可以开发 Plugin 进行扩展（Plugin 更新需要重启） |
| 配置和使用     | 增加了一定的架构复杂度                     | 无需额外部署                                                |

> https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes

### Painless 简介

- 自 ES 5.x 后引入，专门为 ES 设置，扩展了 Java 的语法
- 6.0 开始，ES 只支持 Painless。Grooby ,JavaScript 和 Python 都不在支持
- Painless 支持所有的 Java 的数据类型及 Java API 子集
- Painless Script 具备以下特性
  - 高性能 / 安全
  - 支持显示类型或者动态定义类型

### Painless 的用途

- 可以对文档字段进行加工处理
  - 更新或者删除字段，处理数据聚合操作
  - Script Field： 对返回的字段提前进行计算
  - Function Score：对文档的算分进行处理
- 在 Ingest Pipeline 中执行脚本
- 在 Reindex API，Update By Query 时，对数据进行处理

### 通过 Painless 脚本访问字段

| 上下文               | 语法                   |
| :------------------- | :--------------------- |
| Ingestion            | ctx.field_name         |
| Update               | ctx._source.field_name |
| Search & Aggregation | doc{“field_name”]      |

### 案例 1：Script Processsor

![53][53]

```json
// 增加一个 Script Prcessor
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "description": "to split blog tags",
    "processors": [
      {
        "split": {
          "field": "tags",
          "separator": ","
        }
      },
      {
        "script": {
          "source": """
          if(ctx.containsKey("content")){
            ctx.content_length = ctx.content.length();
          }else{
            ctx.content_length=0;
          }
        """
        }
      },
      {
        "set": {
          "field": "views",
          "value": 0
        }
      }
    ]
  },
  "docs": [
    {
      "_index": "index",
      "_id": "id",
      "_source": {
        "title": "Introducing big data......",
        "tags": "hadoop,elasticsearch,spark",
        "content": "You konw, for big data"
      }
    },
    {
      "_index": "index",
      "_id": "idxx",
      "_source": {
        "title": "Introducing cloud computering",
        "tags": "openstack,k8s",
        "content": "You konw, for cloud"
      }
    }
  ]
}
```

### 案例 2：文档更新计数

![54][54]

```json
DELETE tech_blogs
PUT tech_blogs/_doc/1
{
  "title":"Introducing big data......",
  "tags":"hadoop,elasticsearch,spark",
  "content":"You konw, for big data",
  "views":0
}

POST tech_blogs/_update/1
{
  "script": {
    "source": "ctx._source.views += params.new_views",
    "params": {
      "new_views":100
    }
  }
}

// 查看views计数
POST tech_blogs/_search
```

### 案例 3：搜索时的 Script 字段

![55][55]

```json
GET tech_blogs/_search
{
  "script_fields": {
    "rnd_views": {
      "script": {
        "lang": "painless",
        "source": """
          java.util.Random rnd = new Random();
          doc['views'].value+rnd.nextInt(1000);
        """
      }
    }
  },
  "query": {
    "match_all": {}
  }
}
```

### Script: Inline v.s Stored

![56][56]

```json
//保存脚本在 Cluster State
POST _scripts/update_views
{
  "script":{
    "lang": "painless",
    "source": "ctx._source.views += params.new_views"
  }
}

POST tech_blogs/_update/1
{
  "script": {
    "id": "update_views",
    "params": {
      "new_views":1000
    }
  }
}
```

### 脚本缓存

- 编译的开销相较大
- Elasticsearch 会将甲苯编译后缓存在 Cache 中
  - Inline scripts 和 Stored Scripts 都会被缓存
  - 默认缓存 100 个脚本

| 参数                         | 说明                            |
| :--------------------------- | :------------------------------ |
| script.cache.max_size        | 设置最大缓存数                  |
| script.cache.expire          | 设置缓存超时                    |
| script.max_compilations_rate | 默认5分钟最多75次编译 （75/5m） |

## Elasticsearch 数据建模实例

### 什么是数据建模

- 数据建模（Data modeling），是创建数据模型的过程。
  - 数据模型是对真实世界进行抽象描述的一种工具和方法，实现对现实世界的映射
    - 博客、作者、用户评论
  - 三个过程：概念模型 => 逻辑模型 => 数据模型（第三范式）
    - 数据模型：结合具体的数据库，在满足业务读写性能等需求的前提下，确定最终的定义

### 数据建模：功能需求 + 性能需求

![57][57]

### 如何对字段进行建模

![58][58]

### 字段类型 ： Text v.s Keyword

- Text
  - 用于全文本字段，文本会被 Analyzer 分词
  - 默认不支持聚合分析及排序。需要设置 fielddata 为 true
- Keyword
  - 用于 id ，枚举及不需要分词的文本。例如电话号码，email 地址，手机号码，邮政编码，性别等
  - 适用于 Filter（精确匹配），Sorting 和 Aggregations
- 设置多字段类型
  - 默认会为文本类型设置成 text ，并且设置一个 keyword 的子字段
  - 在处理人类语言时，通过增加 “英文”，“拼音” 和 “标准” 分词器，提高搜索结构

### 字段类型：结构化数据

- 数据类型
  - 尽量选择贴近的类型。例如可以用 byte，就不要用 long
- 枚举类型
  - 设置为 keyword 。即便是数字，也应该设置成 keyword ，获取更好的性能
- 其他
  - 日期、布尔、地理信息

### 检索

- 如不需要检索，排序和聚合分析
  - Enable 设置成 false
- 如不需要检索
  - index 设置成 false
- 对需要检索的字段，可以通过如下配置，设置存储粒度
  - Index_options / Norms : 不需要归一化数据时，可以关闭

### 聚合及排序

- 如不需要检索，排序和聚合分析
  - Enable 设置成 false
- 如不需要排序或者聚合分析功能
  - Doc_values / fielddata 设置成 false
- 更新频繁，聚合查询频繁的 keyword 类型的字段
  - 推荐将 eager_global_ordinals 设置为 true

### 额外的存储

- 是否需要专门存储当前字段数据
  - Store 设置为 true ，可以存储该字段的原始数据
  - 一般结合 _source 的 enabled 为 false 时候使用
- Disable _source ： 节约磁盘，适用于指标型数据
  - 一般建议先考虑增加压缩比
  - 无法看到 _source 字段，无法做 ReIndex，无法做 Update
  - Kibana 中无法做 discovery

### 一个数据建模的实例

- 图书的索引
  - 书名
  - 简介
  - 作者
  - 发行日期
  - 图书封面

![59][59]

```json
PUT books/_doc/1
{
  "title":"Mastering ElasticSearch 5.0",
  "description":"Master the searching, indexing, and aggregation features in ElasticSearch Improve users’ search experience with Elasticsearch’s functionalities and develop your own Elasticsearch plugins",
  "author":"Bharvi Dixit",
  "public_date":"2017",
  "cover_url":"https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg"
}
GET books/_mapping
// return 
{
  "books" : {
    "mappings" : {
      "properties" : {
        "author" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "cover_url" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "description" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "public_date" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "title" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        }
      }
    }
  }
}
```

### 优化字段的设定

- 图书的索引
  - 书名：支持全文和精确匹配
  - 简介：支持全文
  - 作者：精确值
  - 发行日期：日期类型
  - 图书封面：精确值

![60][60]

```json
// 优化字段类型
PUT books
{
  "mappings" : {
    "properties" : {
      "author" : {"type" : "keyword"},
      "cover_url" : {"type" : "keyword","index": false},
      "description" : {"type" : "text"},
      "public_date" : {"type" : "date"},
      "title" : {
        "type" : "text",
        "fields" : {
          "keyword" : {
            "type" : "keyword",
            "ignore_above" : 100
          }
        }
      }
    }
  }
}
// Cover URL index 设置成false，无法对该字段进行搜索
POST books/_search
{
  "query": {
    "term": {
      "cover_url": {
        "value": "https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg"
      }
    }
  }
}

// Cover URL index 设置成false，依然支持聚合分析
POST books/_search
{
  "aggs": {
    "cover": {
      "terms": {
        "field": "cover_url",
        "size": 10
      }
    }
  }
}
```

### 需求变更

- 新需求：增加图书内容的字段，并要求能被搜索同时支持高亮显示
- 新需求会导致 _source 的内容过大
  - Source Filtering 只是传输给客户端进行过滤，Fetch 数据时，ES 节点还是会传输 _source 中的数据
- 解决方法
  - 关闭 _source
  - 然后将每个字段的 “store” 设置成 true

```json
DELETE books
// 新增 Content字段。数据量很大。选择将Source 关闭
PUT books
{
  "mappings" : {
    "_source": {"enabled": false},
    "properties" : {
      "author" : {"type" : "keyword","store": true},
      "cover_url" : {"type" : "keyword","index": false,"store": true},
      "description" : {"type" : "text","store": true},
       "content" : {"type" : "text","store": true},
      "public_date" : {"type" : "date","store": true},
      "title" : {
        "type" : "text",
        "fields" : {
          "keyword" : {
            "type" : "keyword",
            "ignore_above" : 100
          }
        },
        "store": true
      }
    }
  }
}
```

### 查询图书：解决字段过大引发的性能问题

- 返回结果不包含 _source 字段
- 对于需要显示的信息，可以在查询中指定 “store_fields”
- 禁止 _source 字段后，还是支持使用 hignlights API ，高亮显示 content 中的匹配的相关信息

```json
// Index 一本书的信息,包含Content
PUT books/_doc/1
{
  "title":"Mastering ElasticSearch 5.0",
  "description":"Master the searching, indexing, and aggregation features in ElasticSearch Improve users’ search experience with Elasticsearch’s functionalities and develop your own Elasticsearch plugins",
  "content":"The content of the book......Indexing data, aggregation, searching.    something else. something in the way............",
  "author":"Bharvi Dixit",
  "public_date":"2017",
  "cover_url":"https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg"
}

// 查询结果中，Source不包含数据
POST books/_search
{}

// 搜索，通过store 字段显示数据，同时高亮显示 conent的内容
POST books/_search
{
  "stored_fields": ["title","author","public_date"],
  "query": {
    "match": {
      "content": "searching"
    }
  },
  "highlight": {
    "fields": {
      "content":{}
    }
  }
}
```

### Mapping 字段的相关设置

- Enabled - 设置成 false，仅做存储，不支持搜索和聚合分析 （数据保存在_source 中）
- Index - 是否构倒排索引。设置成 false，无法被搜索，但还是支持 aggregation，并出现在 _source
中
- Norms - 如果字段用来过滤和聚合分析，可以关闭，节约存储
- Doc_values - 是否启用 doc_values，用于排序和聚合分析
- Field_data - 如果要对 text 类型启用排序和聚合分析， fielddata 需要设置成true
- Store - 默认不存储，数据默认存储在 _source
- Coerce - 默认开启，是否开启数据类型的自动转换（例如，字符串转数字）
- Multifields 多字段特性
- Dynamic - true / false / strict 控制 Mapping 的自动更新

> https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html

### 一些相关的 API

- Index Template & Dynamic Template
  - 根据索引的名字匹配不同的 Mappings 和 Settings
  - 可以在⼀个 Mapping 上动态的设定字段类型
- Index Alias
  - ⽆需停机，⽆需修改程序，即可进⾏修改
- Update By Query & Reindex

## Elasticsearch 数据建模佳实践

### 建模建议（一）：如何处理关联关系

- Object ： 优先考虑 Denormailzation
- Nested ： 当数据包含多数值对象（对个演员），同时有查询需求
- Child/Parent: 关联文档更新非常频繁时

### Kibana

- Kibana 目前暂不支持 nested 类型 和 parent /child 类型，在未来有可能会支持
- 如果需要使用 Kibana 进行数据分析，在数据建模时仍需要对嵌套和父子关联类型作出取舍

### 建模建议（二）：避免过多字段

- 一个文档中，最好避免大量的字段
  - 过多的字段数不容易维护
  - Mapping 信息保存在 Cluster State 中， 数据量过大，对集群性能会有影响（Cluster State 信息需要和所有的节点同步）
  - 删除或者修改数据需要 reindex
- 默认最大字段数是 1000，可以设置 `index.mapping.total_fields.limit` 限制最大的字段数
- 什么原因会导致文档中会有成百上千的字段？

### Dynamic v.s Strict

- Dynamic （生产环境中，尽量不要打开 Dynamic）
  - true - 未知字段会被自动加入
  - false - 新字段不会被索引，但是会保存在 _source
  - strict - 新增字段不会被索引，文档写入失败
- Strict
  - 可以控制到字段级别

### 一个例子： Cookie Service 的数据

- 来自 Cookie Service 的数据
  - Cookie 的键值对很多
  - 当 Dynamic 设置为 True
  - 同时采用扁平化的设计，必然导致字段数量的膨胀

```json
##索引数据，dynamic mapping 会不断加入新增字段
PUT cookie_service/_doc/1
{
 "url":"www.google.com",
 "cookies":{
   "username":"tom",
   "age":32
 }
}

PUT cookie_service/_doc/2
{
 "url":"www.amazon.com",
 "cookies":{
   "login":"2019-01-01",
   "email":"xyz@abc.com"
 }
}

GET cookie_service/_mapping
```

### 解决方案：Nested Object & Key Value

```json
DELETE cookie_service
// 使用 Nested 对象，增加key/value
PUT cookie_service
{
  "mappings": {
    "properties": {
      "cookies": {
        "type": "nested",
        "properties": {
          "name": {
            "type": "keyword"
          },
          "dateValue": {
            "type": "date"
          },
          "keywordValue": {
            "type": "keyword"
          },
          "IntValue": {
            "type": "integer"
          }
        }
      },
      "url": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      }
    }
  }
}
```

### 写入 & 查询

```json
PUT cookie_service/_doc/1
{
 "url":"www.google.com",
 "cookies":[
    {
      "name":"username",
      "keywordValue":"tom"
    },
    {
      "name":"age",
      "intValue":32
    }
   ]
 }

PUT cookie_service/_doc/2
{
 "url":"www.amazon.com",
 "cookies":[
    {
      "name":"login",
      "dateValue":"2019-01-01"
    },
    {
      "name":"email",
      "IntValue":32
    }
  ]
}

// Nested 查询，通过bool查询进行过滤
POST cookie_service/_search
{
  "query": {
    "nested": {
      "path": "cookies",
      "query": {
        "bool": {
          "filter": [
            {
            "term": {
              "cookies.name": "age"
            }},
            {
              "range":{
                "cookies.intValue":{
                  "gte":30
                }
              }
            }
          ]
        }
      }
    }
  }
}
```

### 通过 Nested 对象保存 Key / Value 的一些不足

- 可以减少字段数量，解决 Cluster State 中 保存过多 Meta 信息的问题，但是
  - 导致查询语句复杂度增加
  - Nested 对象 ，不利于在 Kibana 汇总实现可视化分析

### 建模建议（三）：避免正则查询

- 问题：
  - 正则，通配符查询，前缀查询属于 Term 查询，但是性能不够好
  - 特别是将通配符放在开头，会导致性能的灾难
- 案例：
  - 文档中某个字段包含了 ES 的版本信息，例如 version：“7.1.0”
  - 搜索所有是 bug fix 的版本？每个主要版本号所关联的文档？

```json
// 在Mapping中加入元信息，便于管理
PUT softwares/
{
  "mappings": {
    "_meta": {
      "software_version_mapping": "1.0"
    }
  }
}

GET softwares/_mapping
PUT softwares/_doc/1
{
  "software_version":"7.1.0"
}
```

### 解决方案：将字符串转换为对象

```json
// 优化, 使用inner object
PUT softwares/
{
  "mappings": {
    "_meta": {
      "software_version_mapping": "1.1"
    },
    "properties": {
      "version": {
        "properties": {
          "display_name": {
            "type": "keyword"
          },
          "hot_fix": {
            "type": "byte"
          },
          "marjor": {
            "type": "byte"
          },
          "minor": {
            "type": "byte"
          }
        }
      }
    }
  }
}

// 通过 Inner Object 写入多个文档
PUT softwares/_doc/1
{
  "version": {
    "display_name": "7.1.0",
    "marjor": 7,
    "minor": 1,
    "hot_fix": 0
  }
}

PUT softwares/_doc/2
{
  "version": {
    "display_name": "7.2.0",
    "marjor": 7,
    "minor": 2,
    "hot_fix": 0
  }
}

PUT softwares/_doc/3
{
  "version": {
    "display_name": "7.2.1",
    "marjor": 7,
    "minor": 2,
    "hot_fix": 1
  }
}
```

### 搜索过滤

```json
// 通过 bool 查询，实现 filter 过滤，避免正则查询，大大提升性能。
POST softwares/_search
{
  "query": {
    "bool": {
      "filter": [
        {
          "match": {
            "version.marjor": 7
          }
        },
        {
          "match": {
            "version.minor": 2
          }
        }
      ]
    }
  }
}
```

### 建模建议（四）：避免空置引起的聚合不准

![61][61]

### 使用 Null_Value 解决空值的问题

![62][62]

```json
// Not Null 解决聚合的问题
DELETE ratings
PUT ratings
{
  "mappings": {
      "properties": {
        "rating": {
          "type": "float",
          "null_value": 1.0
        }
      }
    }
}

PUT ratings/_doc/1
{
 "rating":5
}
PUT ratings/_doc/2
{
 "rating":null
}


POST ratings/_search
POST ratings/_search
{
  "size": 0,
  "aggs": {
    "avg": {
      "avg": {
        "field": "rating"
      }
    }
  }
}

POST ratings/_search
{
  "query": {
    "term": {
      "rating": {
        "value": 1
      }
    }
  }
}
```

### 建模建议（五）：为索引的 Mapping 加入 Meta 的信息

- Mappings 设置非常重要，需要从两个维度进行考虑
  - 功能：索引，聚合，排序
  - 性能：存储的开销；内存的开销；搜索的性能
- Mappings 设置是一个迭代的过程
  - 加入新的字段容易（必要时需要 update_by_query）
  - 更新删除字段不允许（需要 Reindex 重建数据）
  - 最好能对 Mappings 加入 Meta 信息，更好的进行版本管理
  - 可以考虑 Mapping 文件上传 git 进行管理

```json
// 在Mapping中加入元信息，便于管理
PUT softwares/
{
  "mappings": {
    "_meta": {
      "software_version_mapping": "1.0"
    }
  }
}
```

## 参考

- 《Elasticsearch核心技术与实战》
- https://www.elastic.co/cn/blog/a-new-era-for-cluster-coordination-in-elasticsearch
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-metrics.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-bucket.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-pipeline.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-nested-query.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-child-query.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-parent-query.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-parent-id-query.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-reindex.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-update-by-query.html
- https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-apis.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html
- https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-lang-spec.html
- https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-api-reference.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/general-recommendations.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-disk-usage.html
- https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html

[1]: /images/big-data/es-06/1.jpg
[2]: /images/big-data/es-06/2.jpg
[3]: /images/big-data/es-06/3.jpg
[4]: /images/big-data/es-06/4.jpg
[5]: /images/big-data/es-06/5.jpg
[6]: /images/big-data/es-06/6.jpg
[7]: /images/big-data/es-06/7.jpg
[8]: /images/big-data/es-06/8.jpg
[9]: /images/big-data/es-06/9.jpg
[10]: /images/big-data/es-06/10.jpg
[11]: /images/big-data/es-06/11.jpg
[12]: /images/big-data/es-06/12.jpg
[13]: /images/big-data/es-06/13.jpg
[14]: /images/big-data/es-06/14.jpg
[15]: /images/big-data/es-06/15.jpg
[16]: /images/big-data/es-06/16.jpg
[17]: /images/big-data/es-06/17.jpg
[18]: /images/big-data/es-06/18.jpg
[19]: /images/big-data/es-06/19.jpg
[20]: /images/big-data/es-06/20.jpg
[21]: /images/big-data/es-06/21.jpg
[22]: /images/big-data/es-06/22.jpg
[23]: /images/big-data/es-06/23.jpg
[24]: /images/big-data/es-06/24.jpg
[25]: /images/big-data/es-06/25.jpg
[26]: /images/big-data/es-06/26.jpg
[27]: /images/big-data/es-06/27.jpg
[28]: /images/big-data/es-06/28.jpg
[29]: /images/big-data/es-06/29.jpg
[30]: /images/big-data/es-06/30.jpg
[31]: /images/big-data/es-06/31.jpg
[32]: /images/big-data/es-06/32.jpg
[33]: /images/big-data/es-06/33.jpg
[34]: /images/big-data/es-06/34.jpg
[35]: /images/big-data/es-06/35.jpg
[36]: /images/big-data/es-06/36.jpg
[37]: /images/big-data/es-06/37.jpg
[38]: /images/big-data/es-06/38.jpg
[39]: /images/big-data/es-06/39.jpg
[40]: /images/big-data/es-06/40.jpg
[41]: /images/big-data/es-06/41.jpg
[42]: /images/big-data/es-06/42.jpg
[43]: /images/big-data/es-06/43.jpg
[44]: /images/big-data/es-06/44.jpg
[45]: /images/big-data/es-06/45.jpg
[46]: /images/big-data/es-06/46.jpg
[47]: /images/big-data/es-06/47.jpg
[48]: /images/big-data/es-06/48.jpg
[49]: /images/big-data/es-06/49.jpg
[50]: /images/big-data/es-06/50.jpg
[51]: /images/big-data/es-06/51.jpg
[52]: /images/big-data/es-06/52.jpg
[53]: /images/big-data/es-06/53.jpg
[54]: /images/big-data/es-06/54.jpg
[55]: /images/big-data/es-06/55.jpg
[56]: /images/big-data/es-06/56.jpg
[57]: /images/big-data/es-06/57.jpg
[58]: /images/big-data/es-06/58.jpg
[59]: /images/big-data/es-06/59.jpg
[60]: /images/big-data/es-06/60.jpg
[61]: /images/big-data/es-06/61.jpg
[62]: /images/big-data/es-06/62.jpg

<style>
  img {
    zoom: 50%;
  }
</style>
